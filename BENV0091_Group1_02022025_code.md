# **Introduction**

This project focuses on predicting day-ahead electricity prices for the NO2 zone in Norway. The analysis incorporates various energy-related data, such as forecasts for load, generation, wind, and solar energy, as well as cross-border physical flows and net transfer capacities. The goal is to build a comprehensive dataset that can be used for predictive modeling.

# **Data Collection**
Data is collected using the **ENTSO-E API**.

The following datasets are retrieved:

1.   **Day-Ahead Prices**: Historical day-ahead electricity prices for the NO2 zone.
2.   **Load Forecasts**: Forecasted electricity demand for multiple areas, including NO2 and neighboring regions.
3.   **Wind and Solar Forecasts**: Forecasted renewable energy production (wind and solar) for relevant zones.
1.   **Generation Forecasts**: Predicted electricity generation capacity for selected regions.
1.   **Net Transfer Capacities (NTC)**: Week-ahead net transfer capacities for specific cross-border connections.
1.   **Cross-Border Physical Flows**: Net flows of electricity across borders involving the NO2 zone.

The analysis spans from October 2023 to September 2024. To account for lagged features, the dataset includes an extended start date.


```python
#!{sys.executable} -m pip install entsoe-py
!pip install entsoe-py
```

    Requirement already satisfied: entsoe-py in /opt/anaconda3/lib/python3.12/site-packages (0.6.15)
    Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (from entsoe-py) (2.32.2)
    Requirement already satisfied: pytz in /opt/anaconda3/lib/python3.12/site-packages (from entsoe-py) (2024.1)
    Requirement already satisfied: beautifulsoup4>=4.11.1 in /opt/anaconda3/lib/python3.12/site-packages (from entsoe-py) (4.12.3)
    Requirement already satisfied: pandas>=2.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from entsoe-py) (2.2.2)
    Requirement already satisfied: soupsieve>1.2 in /opt/anaconda3/lib/python3.12/site-packages (from beautifulsoup4>=4.11.1->entsoe-py) (2.5)
    Requirement already satisfied: numpy>=1.26.0 in /opt/anaconda3/lib/python3.12/site-packages (from pandas>=2.2.0->entsoe-py) (1.26.4)
    Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.12/site-packages (from pandas>=2.2.0->entsoe-py) (2.9.0.post0)
    Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.12/site-packages (from pandas>=2.2.0->entsoe-py) (2023.3)
    Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests->entsoe-py) (2.0.4)
    Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests->entsoe-py) (3.7)
    Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests->entsoe-py) (2.2.2)
    Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests->entsoe-py) (2024.6.2)
    Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas>=2.2.0->entsoe-py) (1.16.0)
    




```python
# 1. Imports and API Data Collection
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from entsoe import EntsoePandasClient
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error
from scipy import stats

# Initialize API Client
client = EntsoePandasClient(api_key='d43c0033-144a-4c29-aa12-98d6d1070332')

# Define date range
start = pd.Timestamp('20231001', tz='Europe/Brussels')
end = pd.Timestamp('20240930', tz='Europe/Brussels')
extended_start = start - pd.Timedelta(days=1)

# Define specific areas and variable mappings
areas_load_forecast = ["NO_2", "NO_1", "NO_5", "DK", "NL", "DE_LU"]
areas_wind_and_solar_forecast = areas_load_forecast  # Same as load forecast areas
areas_generation_forecast = areas_load_forecast  # Same as load forecast areas
ntc_pairs = [
    ("NO_2", "NL"),
    ("NO_2", "DK1"),
    ("NO_2", "DE_LU"),
    ("NO_2", "GB"),
    ("NO_2", "NO_5")
]  # Net transfer capacity

# Cross-Border Physical Flows for NO2 Zone
crossborder_pairs = ntc_pairs  # Use the existing NTC pairs for cross-border flow calculations

data_frames = {}

# Fetch Day-Ahead Prices for NO_2
try:
    data_frames['DA_prices_NO_2'] = client.query_day_ahead_prices("NO_2", start=extended_start, end=end).to_frame(name='DA_prices_NO_2')
    # Add Previous Day's Price as a Feature
    data_frames['DA_prices_NO_2']['Prev_Day_DA_prices_NO_2'] = data_frames['DA_prices_NO_2']['DA_prices_NO_2'].shift(1)
    # Filter to remove the extended day
    data_frames['DA_prices_NO_2'] = data_frames['DA_prices_NO_2'].loc[start:end]
except Exception as e:
    print(f"Failed to fetch DA prices for NO_2: {e}")

# Fetch Load Forecast for multiple areas
for area in areas_load_forecast:
    try:
        data = client.query_load_forecast(area, start=start, end=end).rename(columns={'Forecasted Load': f'Load_forecast_{area}'})
        data_frames[f'Load_forecast_{area}'] = data
    except Exception as e:
        print(f"Failed to fetch Load Forecast for {area}: {e}")

# Fetch Wind and Solar Forecast for multiple areas
for area in areas_wind_and_solar_forecast:
    try:
        data = client.query_wind_and_solar_forecast(area, start=start, end=end)
        data.columns = [f"{col}_{area}" for col in data.columns]  # Consistent column naming
        data_frames[f'Wind_and_Solar_forecast_{area}'] = data
    except Exception as e:
        print(f"Failed to fetch Wind and Solar Forecast for {area}: {e}")

# Fetch Generation Forecast for multiple areas
for area in areas_generation_forecast:
    try:
        data = client.query_generation_forecast(area, start=start, end=end).to_frame(name=f'Generation_forecast_{area}')
        data_frames[f'Generation_forecast_{area}'] = data
    except Exception as e:
        print(f"Failed to fetch Generation Forecast for {area}: {e}")

# Fetch Net Transfer Capacity (Week-Ahead) for specified pairs
for from_area, to_area in ntc_pairs:
    try:
        data = client.query_net_transfer_capacity_weekahead(from_area, to_area, start=start, end=end).to_frame(
            name=f'NTC_WeekAhead_{from_area}_to_{to_area}')
        data_frames[f'NTC_WeekAhead_{from_area}_to_{to_area}'] = data
    except Exception as e:
        print(f"Failed to fetch NTC Week-Ahead from {from_area} to {to_area}: {e}")

# Fetch Aggregate Water Reservoirs and Hydro Storage for NO_2
try:
    data_frames['Aggregate_Water_Reservoirs_NO_2'] = client.query_aggregate_water_reservoirs_and_hydro_storage(
        "NO_2", start=start, end=end).to_frame(name='Aggregate_Water_Reservoirs_NO_2')
except Exception as e:
    print(f"Failed to fetch Aggregate Water Reservoirs for NO_2: {e}")

# Fetch and compute net flows for each pair
def fetch_net_flow(from_area, to_area):
    try:
        flow_1 = client.query_crossborder_flows(from_area, to_area, start=start, end=end)
        flow_2 = client.query_crossborder_flows(to_area, from_area, start=start, end=end)
        net_flow = flow_1 - flow_2
        net_flow.name = f"Net_Flow_{from_area}_to_{to_area}"
        return net_flow.to_frame()
    except Exception as e:
        print(f"Failed to fetch cross-border flows between {from_area} and {to_area}: {e}")
        return pd.DataFrame()

for from_area, to_area in crossborder_pairs:
    data_frames[f"Net_Flow_{from_area}_to_{to_area}"] = fetch_net_flow(from_area, to_area)

```

    Failed to fetch NTC Week-Ahead from NO_2 to DK1: Invalid country code.
    Failed to fetch cross-border flows between NO_2 and DK1: Invalid country code.
    

All datasets are merged into a single DataFrame for analysis, ensuring all datasets align on the same timestamps.


```python
merged_data = pd.concat(data_frames.values(), axis=1)

merged_data.info()
print(merged_data.describe())
print(merged_data.head(10))
```

    <class 'pandas.core.frame.DataFrame'>
    DatetimeIndex: 35042 entries, 2023-09-24 22:00:00+00:00 to 2024-09-29 22:00:00+00:00
    Data columns (total 41 columns):
     #   Column                           Non-Null Count  Dtype  
    ---  ------                           --------------  -----  
     0   DA_prices_NO_2                   8760 non-null   float64
     1   Prev_Day_DA_prices_NO_2          8760 non-null   float64
     2   Load_forecast_NO_2               8760 non-null   float64
     3   Load_forecast_NO_1               8760 non-null   float64
     4   Load_forecast_NO_5               8760 non-null   float64
     5   Load_forecast_DK                 8760 non-null   float64
     6   Load_forecast_NL                 35040 non-null  float64
     7   Load_forecast_DE_LU              35036 non-null  float64
     8   Solar_NO_2                       8760 non-null   float64
     9   Wind Offshore_NO_2               192 non-null    float64
     10  Wind Onshore_NO_2                8760 non-null   float64
     11  Solar_NO_1                       8760 non-null   float64
     12  Wind Offshore_NO_1               192 non-null    float64
     13  Wind Onshore_NO_1                8760 non-null   float64
     14  Solar_NO_5                       8760 non-null   float64
     15  Wind Offshore_NO_5               192 non-null    float64
     16  Wind Onshore_NO_5                8760 non-null   float64
     17  Solar_DK                         8760 non-null   float64
     18  Wind Offshore_DK                 8760 non-null   float64
     19  Wind Onshore_DK                  8736 non-null   float64
     20  Solar_NL                         34944 non-null  float64
     21  Wind Offshore_NL                 34944 non-null  float64
     22  Wind Onshore_NL                  34944 non-null  float64
     23  Solar_DE_LU                      35036 non-null  float64
     24  Wind Offshore_DE_LU              35040 non-null  float64
     25  Wind Onshore_DE_LU               35036 non-null  float64
     26  Generation_forecast_NO_2         8760 non-null   float64
     27  Generation_forecast_NO_1         8760 non-null   float64
     28  Generation_forecast_NO_5         8760 non-null   float64
     29  Generation_forecast_DK           8760 non-null   float64
     30  Generation_forecast_NL           35040 non-null  float64
     31  Generation_forecast_DE_LU        8759 non-null   float64
     32  NTC_WeekAhead_NO_2_to_NL         365 non-null    float64
     33  NTC_WeekAhead_NO_2_to_DE_LU      365 non-null    float64
     34  NTC_WeekAhead_NO_2_to_GB         365 non-null    float64
     35  NTC_WeekAhead_NO_2_to_NO_5       365 non-null    float64
     36  Aggregate_Water_Reservoirs_NO_2  53 non-null     float64
     37  Net_Flow_NO_2_to_NL              21642 non-null  float64
     38  Net_Flow_NO_2_to_DE_LU           35040 non-null  float64
     39  Net_Flow_NO_2_to_GB              21642 non-null  float64
     40  Net_Flow_NO_2_to_NO_5            21642 non-null  float64
    dtypes: float64(41)
    memory usage: 11.2 MB
           DA_prices_NO_2  Prev_Day_DA_prices_NO_2  Load_forecast_NO_2  \
    count     8760.000000              8760.000000         8760.000000   
    mean        54.357993                54.360514         4130.779795   
    std         29.815011                29.813637          762.836480   
    min        -59.960000               -59.960000         2689.000000   
    25%         39.910000                39.910000         3489.000000   
    50%         52.685000                52.685000         4002.000000   
    75%         64.595000                64.595000         4703.000000   
    max        259.860000               259.860000         6418.000000   
    
           Load_forecast_NO_1  Load_forecast_NO_5  Load_forecast_DK  \
    count         8760.000000         8760.000000       8760.000000   
    mean          4103.955822         1936.074772       4173.403653   
    std           1427.047973          328.203893        708.991890   
    min           1860.000000         1241.000000       2527.000000   
    25%           2871.750000         1634.000000       3643.000000   
    50%           3854.500000         1932.000000       4176.000000   
    75%           5240.000000         2211.000000       4680.000000   
    max           8187.000000         2750.000000       6220.000000   
    
           Load_forecast_NL  Load_forecast_DE_LU  Solar_NO_2  Wind Offshore_NO_2  \
    count      35040.000000         35036.000000      8760.0               192.0   
    mean       11261.674772         53107.935324         0.0                 0.0   
    std         2002.413770          9014.360575         0.0                 0.0   
    min         4455.000000         32066.000000         0.0                 0.0   
    25%        10034.750000         45605.000000         0.0                 0.0   
    50%        11095.000000         52700.500000         0.0                 0.0   
    75%        12495.000000         60813.000000         0.0                 0.0   
    max        18088.000000         73424.000000         0.0                 0.0   
    
           ...  Generation_forecast_DE_LU  NTC_WeekAhead_NO_2_to_NL  \
    count  ...                8759.000000                365.000000   
    mean   ...               50046.637059                541.682192   
    std    ...               11279.482505                125.430809   
    min    ...               23424.000000                  0.000000   
    25%    ...               41496.000000                490.000000   
    50%    ...               50270.000000                620.000000   
    75%    ...               58124.500000                620.000000   
    max    ...               85794.000000                620.000000   
    
           NTC_WeekAhead_NO_2_to_DE_LU  NTC_WeekAhead_NO_2_to_GB  \
    count                   365.000000                365.000000   
    mean                   1303.580822               1338.630137   
    std                     303.431749                282.285195   
    min                       0.000000                  0.000000   
    25%                    1400.000000               1400.000000   
    50%                    1400.000000               1400.000000   
    75%                    1400.000000               1400.000000   
    max                    1444.000000               1400.000000   
    
           NTC_WeekAhead_NO_2_to_NO_5  Aggregate_Water_Reservoirs_NO_2  \
    count                  365.000000                     5.300000e+01   
    mean                   475.616438                     2.257289e+07   
    std                    105.780541                     5.554520e+06   
    min                      0.000000                     1.247530e+07   
    25%                    500.000000                     1.799261e+07   
    50%                    500.000000                     2.400778e+07   
    75%                    500.000000                     2.679833e+07   
    max                    500.000000                     2.945568e+07   
    
           Net_Flow_NO_2_to_NL  Net_Flow_NO_2_to_DE_LU  Net_Flow_NO_2_to_GB  \
    count         21642.000000            35040.000000         21642.000000   
    mean            298.977405              520.948002          1157.013770   
    std             404.697610              876.288222           611.616093   
    min            -652.000000            -1446.000000         -1400.000000   
    25%               0.000000                1.000000          1374.000000   
    50%             492.000000              772.000000          1449.000000   
    75%             620.000000             1298.000000          1450.000000   
    max             623.000000             1407.000000          1452.000000   
    
           Net_Flow_NO_2_to_NO_5  
    count           21642.000000  
    mean             -370.618751  
    std               280.375540  
    min              -934.000000  
    25%              -583.000000  
    50%              -438.000000  
    75%              -203.000000  
    max               575.000000  
    
    [8 rows x 41 columns]
                               DA_prices_NO_2  Prev_Day_DA_prices_NO_2  \
    2023-09-24 22:00:00+00:00             NaN                      NaN   
    2023-09-30 22:00:00+00:00           47.68                    49.14   
    2023-09-30 22:15:00+00:00             NaN                      NaN   
    2023-09-30 22:30:00+00:00             NaN                      NaN   
    2023-09-30 22:45:00+00:00             NaN                      NaN   
    2023-09-30 23:00:00+00:00           47.54                    47.68   
    2023-09-30 23:15:00+00:00             NaN                      NaN   
    2023-09-30 23:30:00+00:00             NaN                      NaN   
    2023-09-30 23:45:00+00:00             NaN                      NaN   
    2023-10-01 00:00:00+00:00           47.59                    47.54   
    
                               Load_forecast_NO_2  Load_forecast_NO_1  \
    2023-09-24 22:00:00+00:00                 NaN                 NaN   
    2023-09-30 22:00:00+00:00              3172.0              2695.0   
    2023-09-30 22:15:00+00:00                 NaN                 NaN   
    2023-09-30 22:30:00+00:00                 NaN                 NaN   
    2023-09-30 22:45:00+00:00                 NaN                 NaN   
    2023-09-30 23:00:00+00:00              3190.0              2628.0   
    2023-09-30 23:15:00+00:00                 NaN                 NaN   
    2023-09-30 23:30:00+00:00                 NaN                 NaN   
    2023-09-30 23:45:00+00:00                 NaN                 NaN   
    2023-10-01 00:00:00+00:00              3122.0              2542.0   
    
                               Load_forecast_NO_5  Load_forecast_DK  \
    2023-09-24 22:00:00+00:00                 NaN               NaN   
    2023-09-30 22:00:00+00:00              1750.0            2822.0   
    2023-09-30 22:15:00+00:00                 NaN               NaN   
    2023-09-30 22:30:00+00:00                 NaN               NaN   
    2023-09-30 22:45:00+00:00                 NaN               NaN   
    2023-09-30 23:00:00+00:00              1728.0            2724.0   
    2023-09-30 23:15:00+00:00                 NaN               NaN   
    2023-09-30 23:30:00+00:00                 NaN               NaN   
    2023-09-30 23:45:00+00:00                 NaN               NaN   
    2023-10-01 00:00:00+00:00              1714.0            2682.0   
    
                               Load_forecast_NL  Load_forecast_DE_LU  Solar_NO_2  \
    2023-09-24 22:00:00+00:00               NaN                  NaN         NaN   
    2023-09-30 22:00:00+00:00           11471.0              35974.0         0.0   
    2023-09-30 22:15:00+00:00           11433.0              35592.0         NaN   
    2023-09-30 22:30:00+00:00           11346.0              35250.0         NaN   
    2023-09-30 22:45:00+00:00           11236.0              34925.0         NaN   
    2023-09-30 23:00:00+00:00           11133.0              34592.0         0.0   
    2023-09-30 23:15:00+00:00           11055.0              34294.0         NaN   
    2023-09-30 23:30:00+00:00           10978.0              34030.0         NaN   
    2023-09-30 23:45:00+00:00           10886.0              33752.0         NaN   
    2023-10-01 00:00:00+00:00           10810.0              33488.0         0.0   
    
                               Wind Offshore_NO_2  ...  Generation_forecast_DE_LU  \
    2023-09-24 22:00:00+00:00                 NaN  ...                        NaN   
    2023-09-30 22:00:00+00:00                 NaN  ...                    25009.0   
    2023-09-30 22:15:00+00:00                 NaN  ...                        NaN   
    2023-09-30 22:30:00+00:00                 NaN  ...                        NaN   
    2023-09-30 22:45:00+00:00                 NaN  ...                        NaN   
    2023-09-30 23:00:00+00:00                 NaN  ...                    24460.0   
    2023-09-30 23:15:00+00:00                 NaN  ...                        NaN   
    2023-09-30 23:30:00+00:00                 NaN  ...                        NaN   
    2023-09-30 23:45:00+00:00                 NaN  ...                        NaN   
    2023-10-01 00:00:00+00:00                 NaN  ...                    23718.0   
    
                               NTC_WeekAhead_NO_2_to_NL  \
    2023-09-24 22:00:00+00:00                       NaN   
    2023-09-30 22:00:00+00:00                     420.0   
    2023-09-30 22:15:00+00:00                       NaN   
    2023-09-30 22:30:00+00:00                       NaN   
    2023-09-30 22:45:00+00:00                       NaN   
    2023-09-30 23:00:00+00:00                       NaN   
    2023-09-30 23:15:00+00:00                       NaN   
    2023-09-30 23:30:00+00:00                       NaN   
    2023-09-30 23:45:00+00:00                       NaN   
    2023-10-01 00:00:00+00:00                       NaN   
    
                               NTC_WeekAhead_NO_2_to_DE_LU  \
    2023-09-24 22:00:00+00:00                          NaN   
    2023-09-30 22:00:00+00:00                       1400.0   
    2023-09-30 22:15:00+00:00                          NaN   
    2023-09-30 22:30:00+00:00                          NaN   
    2023-09-30 22:45:00+00:00                          NaN   
    2023-09-30 23:00:00+00:00                          NaN   
    2023-09-30 23:15:00+00:00                          NaN   
    2023-09-30 23:30:00+00:00                          NaN   
    2023-09-30 23:45:00+00:00                          NaN   
    2023-10-01 00:00:00+00:00                          NaN   
    
                               NTC_WeekAhead_NO_2_to_GB  \
    2023-09-24 22:00:00+00:00                       NaN   
    2023-09-30 22:00:00+00:00                    1400.0   
    2023-09-30 22:15:00+00:00                       NaN   
    2023-09-30 22:30:00+00:00                       NaN   
    2023-09-30 22:45:00+00:00                       NaN   
    2023-09-30 23:00:00+00:00                       NaN   
    2023-09-30 23:15:00+00:00                       NaN   
    2023-09-30 23:30:00+00:00                       NaN   
    2023-09-30 23:45:00+00:00                       NaN   
    2023-10-01 00:00:00+00:00                       NaN   
    
                               NTC_WeekAhead_NO_2_to_NO_5  \
    2023-09-24 22:00:00+00:00                         NaN   
    2023-09-30 22:00:00+00:00                       500.0   
    2023-09-30 22:15:00+00:00                         NaN   
    2023-09-30 22:30:00+00:00                         NaN   
    2023-09-30 22:45:00+00:00                         NaN   
    2023-09-30 23:00:00+00:00                         NaN   
    2023-09-30 23:15:00+00:00                         NaN   
    2023-09-30 23:30:00+00:00                         NaN   
    2023-09-30 23:45:00+00:00                         NaN   
    2023-10-01 00:00:00+00:00                         NaN   
    
                               Aggregate_Water_Reservoirs_NO_2  \
    2023-09-24 22:00:00+00:00                       28113654.0   
    2023-09-30 22:00:00+00:00                              NaN   
    2023-09-30 22:15:00+00:00                              NaN   
    2023-09-30 22:30:00+00:00                              NaN   
    2023-09-30 22:45:00+00:00                              NaN   
    2023-09-30 23:00:00+00:00                              NaN   
    2023-09-30 23:15:00+00:00                              NaN   
    2023-09-30 23:30:00+00:00                              NaN   
    2023-09-30 23:45:00+00:00                              NaN   
    2023-10-01 00:00:00+00:00                              NaN   
    
                               Net_Flow_NO_2_to_NL  Net_Flow_NO_2_to_DE_LU  \
    2023-09-24 22:00:00+00:00                  NaN                     NaN   
    2023-09-30 22:00:00+00:00                421.0                  1380.0   
    2023-09-30 22:15:00+00:00                  NaN                  1406.0   
    2023-09-30 22:30:00+00:00                  NaN                  1406.0   
    2023-09-30 22:45:00+00:00                  NaN                  1406.0   
    2023-09-30 23:00:00+00:00                421.0                  1406.0   
    2023-09-30 23:15:00+00:00                  NaN                  1406.0   
    2023-09-30 23:30:00+00:00                  NaN                  1406.0   
    2023-09-30 23:45:00+00:00                  NaN                  1406.0   
    2023-10-01 00:00:00+00:00                421.0                  1406.0   
    
                               Net_Flow_NO_2_to_GB  Net_Flow_NO_2_to_NO_5  
    2023-09-24 22:00:00+00:00                  NaN                    NaN  
    2023-09-30 22:00:00+00:00               1400.0                 -693.0  
    2023-09-30 22:15:00+00:00                  NaN                    NaN  
    2023-09-30 22:30:00+00:00                  NaN                    NaN  
    2023-09-30 22:45:00+00:00                  NaN                    NaN  
    2023-09-30 23:00:00+00:00               1400.0                 -712.0  
    2023-09-30 23:15:00+00:00                  NaN                    NaN  
    2023-09-30 23:30:00+00:00                  NaN                    NaN  
    2023-09-30 23:45:00+00:00                  NaN                    NaN  
    2023-10-01 00:00:00+00:00               1400.0                 -740.0  
    
    [10 rows x 41 columns]
    


```python
merged_data['Net_Flow_NO_2_to_GB']
```




    2023-09-30 22:00:00+00:00    1400.0
    2023-09-30 23:00:00+00:00    1400.0
    2023-10-01 00:00:00+00:00    1400.0
    2023-10-01 01:00:00+00:00    1387.0
    2023-10-01 02:00:00+00:00    1134.0
                                  ...  
    2024-09-29 18:00:00+00:00    1448.0
    2024-09-29 19:00:00+00:00    1449.0
    2024-09-29 20:00:00+00:00    1449.0
    2024-09-29 21:00:00+00:00    1289.0
    2024-09-29 22:00:00+00:00    1289.0
    Name: Net_Flow_NO_2_to_GB, Length: 8760, dtype: float64



Missing values are addressed using forward-fill and backward-fill techniques where appropriate.


```python
# Filter rows where 'DA_prices_NO_2' is not NaN
merged_data = merged_data.dropna(subset=['DA_prices_NO_2'])

# Check the result
print(merged_data.info())


merged_data = merged_data.ffill()
merged_data = merged_data.bfill()
print("After fill the data")
print(merged_data.info())

print(merged_data.head(10))
```

    <class 'pandas.core.frame.DataFrame'>
    DatetimeIndex: 8760 entries, 2023-09-30 22:00:00+00:00 to 2024-09-29 22:00:00+00:00
    Data columns (total 41 columns):
     #   Column                           Non-Null Count  Dtype  
    ---  ------                           --------------  -----  
     0   DA_prices_NO_2                   8760 non-null   float64
     1   Prev_Day_DA_prices_NO_2          8760 non-null   float64
     2   Load_forecast_NO_2               8759 non-null   float64
     3   Load_forecast_NO_1               8759 non-null   float64
     4   Load_forecast_NO_5               8759 non-null   float64
     5   Load_forecast_DK                 8759 non-null   float64
     6   Load_forecast_NL                 8759 non-null   float64
     7   Load_forecast_DE_LU              8758 non-null   float64
     8   Solar_NO_2                       8759 non-null   float64
     9   Wind Offshore_NO_2               192 non-null    float64
     10  Wind Onshore_NO_2                8759 non-null   float64
     11  Solar_NO_1                       8759 non-null   float64
     12  Wind Offshore_NO_1               192 non-null    float64
     13  Wind Onshore_NO_1                8759 non-null   float64
     14  Solar_NO_5                       8759 non-null   float64
     15  Wind Offshore_NO_5               192 non-null    float64
     16  Wind Onshore_NO_5                8759 non-null   float64
     17  Solar_DK                         8759 non-null   float64
     18  Wind Offshore_DK                 8759 non-null   float64
     19  Wind Onshore_DK                  8735 non-null   float64
     20  Solar_NL                         8735 non-null   float64
     21  Wind Offshore_NL                 8735 non-null   float64
     22  Wind Onshore_NL                  8735 non-null   float64
     23  Solar_DE_LU                      8758 non-null   float64
     24  Wind Offshore_DE_LU              8759 non-null   float64
     25  Wind Onshore_DE_LU               8758 non-null   float64
     26  Generation_forecast_NO_2         8759 non-null   float64
     27  Generation_forecast_NO_1         8759 non-null   float64
     28  Generation_forecast_NO_5         8759 non-null   float64
     29  Generation_forecast_DK           8759 non-null   float64
     30  Generation_forecast_NL           8759 non-null   float64
     31  Generation_forecast_DE_LU        8758 non-null   float64
     32  NTC_WeekAhead_NO_2_to_NL         364 non-null    float64
     33  NTC_WeekAhead_NO_2_to_DE_LU      364 non-null    float64
     34  NTC_WeekAhead_NO_2_to_GB         364 non-null    float64
     35  NTC_WeekAhead_NO_2_to_NO_5       364 non-null    float64
     36  Aggregate_Water_Reservoirs_NO_2  52 non-null     float64
     37  Net_Flow_NO_2_to_NL              8759 non-null   float64
     38  Net_Flow_NO_2_to_DE_LU           8759 non-null   float64
     39  Net_Flow_NO_2_to_GB              8759 non-null   float64
     40  Net_Flow_NO_2_to_NO_5            8759 non-null   float64
    dtypes: float64(41)
    memory usage: 2.8 MB
    None
    After fill the data
    <class 'pandas.core.frame.DataFrame'>
    DatetimeIndex: 8760 entries, 2023-09-30 22:00:00+00:00 to 2024-09-29 22:00:00+00:00
    Data columns (total 41 columns):
     #   Column                           Non-Null Count  Dtype  
    ---  ------                           --------------  -----  
     0   DA_prices_NO_2                   8760 non-null   float64
     1   Prev_Day_DA_prices_NO_2          8760 non-null   float64
     2   Load_forecast_NO_2               8760 non-null   float64
     3   Load_forecast_NO_1               8760 non-null   float64
     4   Load_forecast_NO_5               8760 non-null   float64
     5   Load_forecast_DK                 8760 non-null   float64
     6   Load_forecast_NL                 8760 non-null   float64
     7   Load_forecast_DE_LU              8760 non-null   float64
     8   Solar_NO_2                       8760 non-null   float64
     9   Wind Offshore_NO_2               8760 non-null   float64
     10  Wind Onshore_NO_2                8760 non-null   float64
     11  Solar_NO_1                       8760 non-null   float64
     12  Wind Offshore_NO_1               8760 non-null   float64
     13  Wind Onshore_NO_1                8760 non-null   float64
     14  Solar_NO_5                       8760 non-null   float64
     15  Wind Offshore_NO_5               8760 non-null   float64
     16  Wind Onshore_NO_5                8760 non-null   float64
     17  Solar_DK                         8760 non-null   float64
     18  Wind Offshore_DK                 8760 non-null   float64
     19  Wind Onshore_DK                  8760 non-null   float64
     20  Solar_NL                         8760 non-null   float64
     21  Wind Offshore_NL                 8760 non-null   float64
     22  Wind Onshore_NL                  8760 non-null   float64
     23  Solar_DE_LU                      8760 non-null   float64
     24  Wind Offshore_DE_LU              8760 non-null   float64
     25  Wind Onshore_DE_LU               8760 non-null   float64
     26  Generation_forecast_NO_2         8760 non-null   float64
     27  Generation_forecast_NO_1         8760 non-null   float64
     28  Generation_forecast_NO_5         8760 non-null   float64
     29  Generation_forecast_DK           8760 non-null   float64
     30  Generation_forecast_NL           8760 non-null   float64
     31  Generation_forecast_DE_LU        8760 non-null   float64
     32  NTC_WeekAhead_NO_2_to_NL         8760 non-null   float64
     33  NTC_WeekAhead_NO_2_to_DE_LU      8760 non-null   float64
     34  NTC_WeekAhead_NO_2_to_GB         8760 non-null   float64
     35  NTC_WeekAhead_NO_2_to_NO_5       8760 non-null   float64
     36  Aggregate_Water_Reservoirs_NO_2  8760 non-null   float64
     37  Net_Flow_NO_2_to_NL              8760 non-null   float64
     38  Net_Flow_NO_2_to_DE_LU           8760 non-null   float64
     39  Net_Flow_NO_2_to_GB              8760 non-null   float64
     40  Net_Flow_NO_2_to_NO_5            8760 non-null   float64
    dtypes: float64(41)
    memory usage: 2.8 MB
    None
                               DA_prices_NO_2  Prev_Day_DA_prices_NO_2  \
    2023-09-30 22:00:00+00:00           47.68                    49.14   
    2023-09-30 23:00:00+00:00           47.54                    47.68   
    2023-10-01 00:00:00+00:00           47.59                    47.54   
    2023-10-01 01:00:00+00:00           47.74                    47.59   
    2023-10-01 02:00:00+00:00           46.97                    47.74   
    2023-10-01 03:00:00+00:00           47.45                    46.97   
    2023-10-01 04:00:00+00:00           50.00                    47.45   
    2023-10-01 05:00:00+00:00           50.32                    50.00   
    2023-10-01 06:00:00+00:00           50.39                    50.32   
    2023-10-01 07:00:00+00:00           50.06                    50.39   
    
                               Load_forecast_NO_2  Load_forecast_NO_1  \
    2023-09-30 22:00:00+00:00              3172.0              2695.0   
    2023-09-30 23:00:00+00:00              3190.0              2628.0   
    2023-10-01 00:00:00+00:00              3122.0              2542.0   
    2023-10-01 01:00:00+00:00              3094.0              2475.0   
    2023-10-01 02:00:00+00:00              3097.0              2455.0   
    2023-10-01 03:00:00+00:00              3126.0              2524.0   
    2023-10-01 04:00:00+00:00              3108.0              2555.0   
    2023-10-01 05:00:00+00:00              3187.0              2631.0   
    2023-10-01 06:00:00+00:00              3273.0              2804.0   
    2023-10-01 07:00:00+00:00              3381.0              2937.0   
    
                               Load_forecast_NO_5  Load_forecast_DK  \
    2023-09-30 22:00:00+00:00              1750.0            2822.0   
    2023-09-30 23:00:00+00:00              1728.0            2724.0   
    2023-10-01 00:00:00+00:00              1714.0            2682.0   
    2023-10-01 01:00:00+00:00              1695.0            2628.0   
    2023-10-01 02:00:00+00:00              1718.0            2630.0   
    2023-10-01 03:00:00+00:00              1704.0            2671.0   
    2023-10-01 04:00:00+00:00              1713.0            2807.0   
    2023-10-01 05:00:00+00:00              1726.0            2990.0   
    2023-10-01 06:00:00+00:00              1761.0            3240.0   
    2023-10-01 07:00:00+00:00              1764.0            3458.0   
    
                               Load_forecast_NL  Load_forecast_DE_LU  Solar_NO_2  \
    2023-09-30 22:00:00+00:00           11471.0              35974.0         0.0   
    2023-09-30 23:00:00+00:00           11133.0              34592.0         0.0   
    2023-10-01 00:00:00+00:00           10810.0              33488.0         0.0   
    2023-10-01 01:00:00+00:00           10575.0              33191.0         0.0   
    2023-10-01 02:00:00+00:00           10494.0              33419.0         0.0   
    2023-10-01 03:00:00+00:00           10438.0              33945.0         0.0   
    2023-10-01 04:00:00+00:00           10426.0              34598.0         0.0   
    2023-10-01 05:00:00+00:00           10315.0              35932.0         0.0   
    2023-10-01 06:00:00+00:00           10070.0              38093.0         0.0   
    2023-10-01 07:00:00+00:00            9129.0              41772.0         0.0   
    
                               Wind Offshore_NO_2  ...  Generation_forecast_DE_LU  \
    2023-09-30 22:00:00+00:00                 0.0  ...                    25009.0   
    2023-09-30 23:00:00+00:00                 0.0  ...                    24460.0   
    2023-10-01 00:00:00+00:00                 0.0  ...                    23718.0   
    2023-10-01 01:00:00+00:00                 0.0  ...                    23937.0   
    2023-10-01 02:00:00+00:00                 0.0  ...                    24512.0   
    2023-10-01 03:00:00+00:00                 0.0  ...                    25550.0   
    2023-10-01 04:00:00+00:00                 0.0  ...                    26477.0   
    2023-10-01 05:00:00+00:00                 0.0  ...                    28497.0   
    2023-10-01 06:00:00+00:00                 0.0  ...                    33567.0   
    2023-10-01 07:00:00+00:00                 0.0  ...                    40459.0   
    
                               NTC_WeekAhead_NO_2_to_NL  \
    2023-09-30 22:00:00+00:00                     420.0   
    2023-09-30 23:00:00+00:00                     420.0   
    2023-10-01 00:00:00+00:00                     420.0   
    2023-10-01 01:00:00+00:00                     420.0   
    2023-10-01 02:00:00+00:00                     420.0   
    2023-10-01 03:00:00+00:00                     420.0   
    2023-10-01 04:00:00+00:00                     420.0   
    2023-10-01 05:00:00+00:00                     420.0   
    2023-10-01 06:00:00+00:00                     420.0   
    2023-10-01 07:00:00+00:00                     420.0   
    
                               NTC_WeekAhead_NO_2_to_DE_LU  \
    2023-09-30 22:00:00+00:00                       1400.0   
    2023-09-30 23:00:00+00:00                       1400.0   
    2023-10-01 00:00:00+00:00                       1400.0   
    2023-10-01 01:00:00+00:00                       1400.0   
    2023-10-01 02:00:00+00:00                       1400.0   
    2023-10-01 03:00:00+00:00                       1400.0   
    2023-10-01 04:00:00+00:00                       1400.0   
    2023-10-01 05:00:00+00:00                       1400.0   
    2023-10-01 06:00:00+00:00                       1400.0   
    2023-10-01 07:00:00+00:00                       1400.0   
    
                               NTC_WeekAhead_NO_2_to_GB  \
    2023-09-30 22:00:00+00:00                    1400.0   
    2023-09-30 23:00:00+00:00                    1400.0   
    2023-10-01 00:00:00+00:00                    1400.0   
    2023-10-01 01:00:00+00:00                    1400.0   
    2023-10-01 02:00:00+00:00                    1400.0   
    2023-10-01 03:00:00+00:00                    1400.0   
    2023-10-01 04:00:00+00:00                    1400.0   
    2023-10-01 05:00:00+00:00                    1400.0   
    2023-10-01 06:00:00+00:00                    1400.0   
    2023-10-01 07:00:00+00:00                    1400.0   
    
                               NTC_WeekAhead_NO_2_to_NO_5  \
    2023-09-30 22:00:00+00:00                       500.0   
    2023-09-30 23:00:00+00:00                       500.0   
    2023-10-01 00:00:00+00:00                       500.0   
    2023-10-01 01:00:00+00:00                       500.0   
    2023-10-01 02:00:00+00:00                       500.0   
    2023-10-01 03:00:00+00:00                       500.0   
    2023-10-01 04:00:00+00:00                       500.0   
    2023-10-01 05:00:00+00:00                       500.0   
    2023-10-01 06:00:00+00:00                       500.0   
    2023-10-01 07:00:00+00:00                       500.0   
    
                               Aggregate_Water_Reservoirs_NO_2  \
    2023-09-30 22:00:00+00:00                       28570242.0   
    2023-09-30 23:00:00+00:00                       28570242.0   
    2023-10-01 00:00:00+00:00                       28570242.0   
    2023-10-01 01:00:00+00:00                       28570242.0   
    2023-10-01 02:00:00+00:00                       28570242.0   
    2023-10-01 03:00:00+00:00                       28570242.0   
    2023-10-01 04:00:00+00:00                       28570242.0   
    2023-10-01 05:00:00+00:00                       28570242.0   
    2023-10-01 06:00:00+00:00                       28570242.0   
    2023-10-01 07:00:00+00:00                       28570242.0   
    
                               Net_Flow_NO_2_to_NL  Net_Flow_NO_2_to_DE_LU  \
    2023-09-30 22:00:00+00:00                421.0                  1380.0   
    2023-09-30 23:00:00+00:00                421.0                  1406.0   
    2023-10-01 00:00:00+00:00                421.0                  1406.0   
    2023-10-01 01:00:00+00:00                421.0                  1406.0   
    2023-10-01 02:00:00+00:00                422.0                  1406.0   
    2023-10-01 03:00:00+00:00                422.0                  1406.0   
    2023-10-01 04:00:00+00:00                422.0                  1372.0   
    2023-10-01 05:00:00+00:00                422.0                  1366.0   
    2023-10-01 06:00:00+00:00                422.0                  1324.0   
    2023-10-01 07:00:00+00:00                412.0                  1227.0   
    
                               Net_Flow_NO_2_to_GB  Net_Flow_NO_2_to_NO_5  
    2023-09-30 22:00:00+00:00               1400.0                 -693.0  
    2023-09-30 23:00:00+00:00               1400.0                 -712.0  
    2023-10-01 00:00:00+00:00               1400.0                 -740.0  
    2023-10-01 01:00:00+00:00               1387.0                 -753.0  
    2023-10-01 02:00:00+00:00               1134.0                 -752.0  
    2023-10-01 03:00:00+00:00               1213.0                 -785.0  
    2023-10-01 04:00:00+00:00               1380.0                 -747.0  
    2023-10-01 05:00:00+00:00               1399.0                 -750.0  
    2023-10-01 06:00:00+00:00               1400.0                 -765.0  
    2023-10-01 07:00:00+00:00               1400.0                 -784.0  
    
    [10 rows x 41 columns]
    

# **Exploratory Data Analysis (EDA)**

EDA is conducted to understand the distributions, relationships, and variability of the collected data:
- **Target Variable**: The distribution of day-ahead prices (`DA_prices_NO_2`) is analyzed for trends and seasonality.
- **Feature Distributions**: Boxplots and histograms reveal variability and outliers in key features.
- **Correlation Analysis**: A heatmap highlights relationships between features and the target variable.
- **Temporal Patterns**: Trends in electricity prices and other features over time are visualized.



```python
# Plot time-series of DA_prices_NO_2
merged_data["DA_prices_NO_2"].plot(figsize=(12, 6))
plt.title("Time Series of DA_prices_NO_2")
plt.xlabel("Date")
plt.ylabel("Price (EUR/MWh)")
plt.grid(True, which='both', linestyle='--', linewidth=0.5, alpha=0.7)
plt.show()


# Visualize the distribution of the target variable
sns.histplot(merged_data["DA_prices_NO_2"], kde=True, color='blue')
plt.title('Distribution of DA_prices_NO_2')
plt.xlabel('Price (EUR/MWh)')
plt.ylabel('Frequency')
plt.show()

# Calculate mean and standard deviation of the target variable
mean_price = merged_data["DA_prices_NO_2"].mean()
std_price = merged_data["DA_prices_NO_2"].std()
print(f"Mean Price: {mean_price:.2f} EUR/MWh, Standard Deviation: {std_price:.2f} EUR/MWh")

```


    
![png](output_11_0.png)
    



    
![png](output_11_1.png)
    


    Mean Price: 54.36 EUR/MWh, Standard Deviation: 29.82 EUR/MWh
    


```python
# Visualize the features

# Determine the number of columns in merged_data
num_plots = len(merged_data.columns)

# Dynamically calculate rows and columns
num_cols = 4
num_rows = (num_plots + num_cols - 1) // num_cols

# Create the figure with adjusted size
plt.figure(figsize=(15, num_rows * 5))

# Plot a box plot for each column in merged_data
for i, column in enumerate(merged_data.columns, start=1):
    plt.subplot(num_rows, num_cols, i)
    sns.boxplot(y=merged_data[column], color=np.random.rand(3,))
    plt.title(f'Box Plot of {column}', fontsize=10)
    plt.xlabel('')
    plt.ylabel('')

plt.tight_layout()  # Prevent overlap
plt.show()

```


    
![png](output_12_0.png)
    



```python
# Identify features with all zero values
all_zero_features = [col for col in merged_data.columns if (merged_data[col] == 0).all()]

# Identify features with 25%, 50%, and 75% values being the same (low variability)
low_variability_features = [
    col for col in merged_data.columns
    if merged_data[col].describe()[['25%', '50%', '75%']].nunique() == 1
]

# Combine both lists of features to drop
features_to_drop = set(all_zero_features + low_variability_features)

# Drop these features from the DataFrame
merged_data = merged_data.drop(columns=features_to_drop)

print(f"Removed features: {features_to_drop}")

```

    Removed features: {'NTC_WeekAhead_NO_2_to_GB', 'NTC_WeekAhead_NO_2_to_NO_5', 'Wind Offshore_NO_2', 'Wind Onshore_NO_5', 'Wind Offshore_NO_5', 'Wind Offshore_NO_1', 'Solar_NO_1', 'NTC_WeekAhead_NO_2_to_DE_LU', 'Solar_NO_2', 'Solar_NO_5'}
    


```python
print(merged_data.isna().sum())
merged_data.describe()
```

    DA_prices_NO_2                     0
    Prev_Day_DA_prices_NO_2            0
    Load_forecast_NO_2                 0
    Load_forecast_NO_1                 0
    Load_forecast_NO_5                 0
    Load_forecast_DK                   0
    Load_forecast_NL                   0
    Load_forecast_DE_LU                0
    Wind Onshore_NO_2                  0
    Wind Onshore_NO_1                  0
    Solar_DK                           0
    Wind Offshore_DK                   0
    Wind Onshore_DK                    0
    Solar_NL                           0
    Wind Offshore_NL                   0
    Wind Onshore_NL                    0
    Solar_DE_LU                        0
    Wind Offshore_DE_LU                0
    Wind Onshore_DE_LU                 0
    Generation_forecast_NO_2           0
    Generation_forecast_NO_1           0
    Generation_forecast_NO_5           0
    Generation_forecast_DK             0
    Generation_forecast_NL             0
    Generation_forecast_DE_LU          0
    NTC_WeekAhead_NO_2_to_NL           0
    Aggregate_Water_Reservoirs_NO_2    0
    Net_Flow_NO_2_to_NL                0
    Net_Flow_NO_2_to_DE_LU             0
    Net_Flow_NO_2_to_GB                0
    Net_Flow_NO_2_to_NO_5              0
    dtype: int64
    




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>DA_prices_NO_2</th>
      <th>Prev_Day_DA_prices_NO_2</th>
      <th>Load_forecast_NO_2</th>
      <th>Load_forecast_NO_1</th>
      <th>Load_forecast_NO_5</th>
      <th>Load_forecast_DK</th>
      <th>Load_forecast_NL</th>
      <th>Load_forecast_DE_LU</th>
      <th>Wind Onshore_NO_2</th>
      <th>Wind Onshore_NO_1</th>
      <th>...</th>
      <th>Generation_forecast_NO_5</th>
      <th>Generation_forecast_DK</th>
      <th>Generation_forecast_NL</th>
      <th>Generation_forecast_DE_LU</th>
      <th>NTC_WeekAhead_NO_2_to_NL</th>
      <th>Aggregate_Water_Reservoirs_NO_2</th>
      <th>Net_Flow_NO_2_to_NL</th>
      <th>Net_Flow_NO_2_to_DE_LU</th>
      <th>Net_Flow_NO_2_to_GB</th>
      <th>Net_Flow_NO_2_to_NO_5</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>8760.000000</td>
      <td>8760.000000</td>
      <td>8760.000000</td>
      <td>8760.000000</td>
      <td>8760.000000</td>
      <td>8760.000000</td>
      <td>8760.000000</td>
      <td>8760.000000</td>
      <td>8760.000000</td>
      <td>8760.000000</td>
      <td>...</td>
      <td>8760.000000</td>
      <td>8760.000000</td>
      <td>8760.000000</td>
      <td>8760.000000</td>
      <td>8760.000000</td>
      <td>8.760000e+03</td>
      <td>8760.000000</td>
      <td>8760.000000</td>
      <td>8760.000000</td>
      <td>8760.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>54.357993</td>
      <td>54.360514</td>
      <td>4130.778995</td>
      <td>4103.978425</td>
      <td>1936.072603</td>
      <td>4173.412215</td>
      <td>11259.921119</td>
      <td>53135.367922</td>
      <td>541.663813</td>
      <td>98.084475</td>
      <td>...</td>
      <td>3529.955936</td>
      <td>3678.568151</td>
      <td>8656.675799</td>
      <td>50046.210959</td>
      <td>541.674201</td>
      <td>2.248489e+07</td>
      <td>243.719863</td>
      <td>521.200228</td>
      <td>1025.001712</td>
      <td>-302.068037</td>
    </tr>
    <tr>
      <th>std</th>
      <td>29.815011</td>
      <td>29.813637</td>
      <td>762.836588</td>
      <td>1427.036108</td>
      <td>328.204525</td>
      <td>708.982749</td>
      <td>2001.085712</td>
      <td>9003.164592</td>
      <td>406.349001</td>
      <td>79.946867</td>
      <td>...</td>
      <td>1323.875692</td>
      <td>1454.529968</td>
      <td>2151.581300</td>
      <td>11278.552329</td>
      <td>125.271548</td>
      <td>5.501561e+06</td>
      <td>411.753360</td>
      <td>873.601268</td>
      <td>694.906476</td>
      <td>301.405171</td>
    </tr>
    <tr>
      <th>min</th>
      <td>-59.960000</td>
      <td>-59.960000</td>
      <td>2689.000000</td>
      <td>1860.000000</td>
      <td>1241.000000</td>
      <td>2527.000000</td>
      <td>4532.000000</td>
      <td>32066.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>...</td>
      <td>3.000000</td>
      <td>372.000000</td>
      <td>3777.000000</td>
      <td>23424.000000</td>
      <td>0.000000</td>
      <td>1.247530e+07</td>
      <td>-650.000000</td>
      <td>-1442.000000</td>
      <td>-1400.000000</td>
      <td>-923.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>39.910000</td>
      <td>39.910000</td>
      <td>3489.000000</td>
      <td>2871.750000</td>
      <td>1634.000000</td>
      <td>3643.000000</td>
      <td>10025.000000</td>
      <td>45654.500000</td>
      <td>174.000000</td>
      <td>31.000000</td>
      <td>...</td>
      <td>2526.000000</td>
      <td>2610.000000</td>
      <td>7085.000000</td>
      <td>41498.000000</td>
      <td>490.000000</td>
      <td>1.799261e+07</td>
      <td>0.000000</td>
      <td>8.000000</td>
      <td>771.000000</td>
      <td>-543.000000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>52.685000</td>
      <td>52.685000</td>
      <td>4002.000000</td>
      <td>3854.500000</td>
      <td>1932.000000</td>
      <td>4176.000000</td>
      <td>11088.000000</td>
      <td>52713.500000</td>
      <td>449.000000</td>
      <td>73.000000</td>
      <td>...</td>
      <td>3456.000000</td>
      <td>3582.500000</td>
      <td>8341.500000</td>
      <td>50269.000000</td>
      <td>620.000000</td>
      <td>2.400778e+07</td>
      <td>422.000000</td>
      <td>771.000000</td>
      <td>1400.000000</td>
      <td>-343.000000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>64.595000</td>
      <td>64.595000</td>
      <td>4703.000000</td>
      <td>5240.000000</td>
      <td>2211.000000</td>
      <td>4680.000000</td>
      <td>12488.250000</td>
      <td>60846.000000</td>
      <td>896.250000</td>
      <td>153.000000</td>
      <td>...</td>
      <td>4465.000000</td>
      <td>4734.000000</td>
      <td>9994.250000</td>
      <td>58122.750000</td>
      <td>620.000000</td>
      <td>2.679833e+07</td>
      <td>620.000000</td>
      <td>1294.250000</td>
      <td>1450.000000</td>
      <td>-96.000000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>259.860000</td>
      <td>259.860000</td>
      <td>6418.000000</td>
      <td>8187.000000</td>
      <td>2750.000000</td>
      <td>6220.000000</td>
      <td>18088.000000</td>
      <td>73278.000000</td>
      <td>1336.000000</td>
      <td>319.000000</td>
      <td>...</td>
      <td>6636.000000</td>
      <td>8684.000000</td>
      <td>15966.000000</td>
      <td>85794.000000</td>
      <td>620.000000</td>
      <td>2.945568e+07</td>
      <td>622.000000</td>
      <td>1407.000000</td>
      <td>1452.000000</td>
      <td>575.000000</td>
    </tr>
  </tbody>
</table>
<p>8 rows  31 columns</p>
</div>




```python
# Outlier Detection
# Calculate IQR for each numeric column
Q1 = merged_data.quantile(0.25)  # First quartile (25th percentile)
Q3 = merged_data.quantile(0.75)  # Third quartile (75th percentile)
IQR = Q3 - Q1  # Interquartile range

# Define the outlier threshold
lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR

# Filter out rows where any column's value is an outlier
merged_data_no_outliers = merged_data[~((merged_data < lower_bound) | (merged_data > upper_bound)).any(axis=1)]

# Data Visualization: Box Plots After Removing Outliers

plt.figure(figsize=(15, num_rows * 5))

# Plot a box plot for each column in merged_data_no_outliers (after removing outliers)
for i, column in enumerate(merged_data_no_outliers.columns, start=1):
    plt.subplot(num_rows, num_cols, i)
    sns.boxplot(y=merged_data_no_outliers[column], color=np.random.rand(3,))
    plt.title(f'Box Plot of {column}', fontsize=10)
    plt.xlabel('')
    plt.ylabel('')

plt.tight_layout()
plt.show()
```


    
![png](output_15_0.png)
    



```python
print("After removing outliers:")
print(merged_data_no_outliers.info())
```

    After removing outliers:
    <class 'pandas.core.frame.DataFrame'>
    DatetimeIndex: 5854 entries, 2023-09-30 22:00:00+00:00 to 2024-09-29 22:00:00+00:00
    Data columns (total 31 columns):
     #   Column                           Non-Null Count  Dtype  
    ---  ------                           --------------  -----  
     0   DA_prices_NO_2                   5854 non-null   float64
     1   Prev_Day_DA_prices_NO_2          5854 non-null   float64
     2   Load_forecast_NO_2               5854 non-null   float64
     3   Load_forecast_NO_1               5854 non-null   float64
     4   Load_forecast_NO_5               5854 non-null   float64
     5   Load_forecast_DK                 5854 non-null   float64
     6   Load_forecast_NL                 5854 non-null   float64
     7   Load_forecast_DE_LU              5854 non-null   float64
     8   Wind Onshore_NO_2                5854 non-null   float64
     9   Wind Onshore_NO_1                5854 non-null   float64
     10  Solar_DK                         5854 non-null   float64
     11  Wind Offshore_DK                 5854 non-null   float64
     12  Wind Onshore_DK                  5854 non-null   float64
     13  Solar_NL                         5854 non-null   float64
     14  Wind Offshore_NL                 5854 non-null   float64
     15  Wind Onshore_NL                  5854 non-null   float64
     16  Solar_DE_LU                      5854 non-null   float64
     17  Wind Offshore_DE_LU              5854 non-null   float64
     18  Wind Onshore_DE_LU               5854 non-null   float64
     19  Generation_forecast_NO_2         5854 non-null   float64
     20  Generation_forecast_NO_1         5854 non-null   float64
     21  Generation_forecast_NO_5         5854 non-null   float64
     22  Generation_forecast_DK           5854 non-null   float64
     23  Generation_forecast_NL           5854 non-null   float64
     24  Generation_forecast_DE_LU        5854 non-null   float64
     25  NTC_WeekAhead_NO_2_to_NL         5854 non-null   float64
     26  Aggregate_Water_Reservoirs_NO_2  5854 non-null   float64
     27  Net_Flow_NO_2_to_NL              5854 non-null   float64
     28  Net_Flow_NO_2_to_DE_LU           5854 non-null   float64
     29  Net_Flow_NO_2_to_GB              5854 non-null   float64
     30  Net_Flow_NO_2_to_NO_5            5854 non-null   float64
    dtypes: float64(31)
    memory usage: 1.4 MB
    None
    


```python
# Add a 'Weekday' column (0=Monday, 6=Sunday) and a 'Weekend' column (1=Weekend, 0=Weekday)
merged_data_no_outliers['Weekday'] = merged_data_no_outliers.index.dayofweek
merged_data_no_outliers['Is_Weekend'] = (merged_data_no_outliers['Weekday'] >= 5).astype(int)

# Load forecasts on weekdays vs weekends
plt.figure(figsize=(6, 4))
sns.boxplot(data=merged_data_no_outliers, x='Is_Weekend', y='Load_forecast_NO_2', palette='coolwarm')
plt.xticks([0, 1], ['Weekday', 'Weekend'])
plt.title('Load Forecast Variability: Weekday vs Weekend')
plt.xlabel('Day Type')
plt.ylabel('Load Forecast (MW)')
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.show()

# NTC values against day-ahead prices
plt.figure(figsize=(6, 4))
sns.scatterplot(data=merged_data_no_outliers, x='NTC_WeekAhead_NO_2_to_NL', y='DA_prices_NO_2', alpha=0.7)
plt.title('NTC vs Day-Ahead Prices')
plt.xlabel('Net Transfer Capacity (MW)')
plt.ylabel('Day-Ahead Prices (EUR/MWh)')
plt.grid(True, linestyle='--', alpha=0.7)
plt.show()

# Net flows against day-ahead prices
plt.figure(figsize=(6, 4))
sns.scatterplot(data=merged_data_no_outliers, x='Net_Flow_NO_2_to_GB', y='DA_prices_NO_2', alpha=0.7)
plt.title('Net Flow vs Day-Ahead Prices')
plt.xlabel('Net Flow (MW)')
plt.ylabel('Day-Ahead Prices (EUR/MWh)')
plt.grid(True, linestyle='--', alpha=0.7)
plt.show()

```

    C:\Users\amun0\AppData\Local\Temp\ipykernel_9176\689315288.py:2: SettingWithCopyWarning: 
    A value is trying to be set on a copy of a slice from a DataFrame.
    Try using .loc[row_indexer,col_indexer] = value instead
    
    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
      merged_data_no_outliers['Weekday'] = merged_data_no_outliers.index.dayofweek
    C:\Users\amun0\AppData\Local\Temp\ipykernel_9176\689315288.py:3: SettingWithCopyWarning: 
    A value is trying to be set on a copy of a slice from a DataFrame.
    Try using .loc[row_indexer,col_indexer] = value instead
    
    See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
      merged_data_no_outliers['Is_Weekend'] = (merged_data_no_outliers['Weekday'] >= 5).astype(int)
    C:\Users\amun0\AppData\Local\Temp\ipykernel_9176\689315288.py:7: FutureWarning: 
    
    Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.
    
      sns.boxplot(data=merged_data_no_outliers, x='Is_Weekend', y='Load_forecast_NO_2', palette='coolwarm')
    


    
![png](output_17_1.png)
    



    
![png](output_17_2.png)
    



    
![png](output_17_3.png)
    



```python
print(merged_data_no_outliers.Weekday)
```

    2023-09-30 22:00:00+00:00    5
    2023-09-30 23:00:00+00:00    5
    2023-10-01 00:00:00+00:00    6
    2023-10-01 01:00:00+00:00    6
    2023-10-01 02:00:00+00:00    6
                                ..
    2024-09-29 18:00:00+00:00    6
    2024-09-29 19:00:00+00:00    6
    2024-09-29 20:00:00+00:00    6
    2024-09-29 21:00:00+00:00    6
    2024-09-29 22:00:00+00:00    6
    Name: Weekday, Length: 5854, dtype: int32
    


```python
# Correlation Matrix Heatmap

threshold = 0.1

correlation_matrix = merged_data_no_outliers.corr()

# Filter out features with low correlation to the target or low maximum correlation overall
low_corr_features = [
    col for col in correlation_matrix.columns
    if (abs(correlation_matrix.loc['DA_prices_NO_2', col]) < threshold) or
       (correlation_matrix[col].abs().max() < threshold)
]

# Filter the correlation matrix to exclude low-correlation features
filtered_corr_matrix = correlation_matrix.drop(index=low_corr_features, columns=low_corr_features)

# Mask the upper triangle of the filtered correlation matrix
mask = np.triu(np.ones_like(filtered_corr_matrix, dtype=bool))

# Create the heatmap
plt.figure(figsize=(12, 10))
sns.heatmap(filtered_corr_matrix, annot=True, cmap='coolwarm', cbar=True,
            mask=mask, annot_kws={"size": 8}, fmt='.2f', square=True)

plt.xticks(rotation=45, ha='right')
plt.yticks(rotation=0, ha='right')
plt.title('Filtered Correlation Matrix (Triangle Format)')

plt.tight_layout()
plt.show()


```


    
![png](output_19_0.png)
    



```python
# Generate pair plots for the entire DataFrame
sns.pairplot(merged_data_no_outliers)
plt.show()
```


    
![png](output_20_0.png)
    



```python
# Determine the number of columns
number_cols = merged_data_no_outliers.shape[1]

slice_size = 4

# Iterate over the dataset, slicing it into chunks of 4 columns
for start_col in range(0, number_cols, slice_size):

    end_col = min(start_col + slice_size, number_cols)
    data_slice = merged_data_no_outliers.iloc[:, start_col:end_col]


    print(f"Visualizing columns {start_col + 1} to {end_col}: {list(data_slice.columns)}")


    sns.pairplot(data_slice,plot_kws={'s': 10})
    plt.show()

```

    Visualizing columns 1 to 4: ['DA_prices_NO_2', 'Prev_Day_DA_prices_NO_2', 'Load_forecast_NO_2', 'Load_forecast_NO_5']
    


    
![png](output_21_1.png)
    


    Visualizing columns 5 to 8: ['Load_forecast_DK', 'Load_forecast_NL', 'Load_forecast_DE_LU', 'Wind Onshore_NO_2']
    


    
![png](output_21_3.png)
    


    Visualizing columns 9 to 12: ['Wind Onshore_NO_1', 'Solar_DK', 'Wind Offshore_DK', 'Wind Onshore_DK']
    


    
![png](output_21_5.png)
    


    Visualizing columns 13 to 16: ['Solar_NL', 'Wind Offshore_NL', 'Wind Onshore_NL', 'Solar_DE_LU']
    


    
![png](output_21_7.png)
    


    Visualizing columns 17 to 20: ['Wind Offshore_DE_LU', 'Wind Onshore_DE_LU', 'Generation_forecast_NO_2', 'Generation_forecast_NO_1']
    


    
![png](output_21_9.png)
    


    Visualizing columns 21 to 24: ['Generation_forecast_NO_5', 'Generation_forecast_DK', 'Generation_forecast_NL', 'Generation_forecast_DE_LU']
    


    
![png](output_21_11.png)
    


    Visualizing columns 25 to 28: ['NTC_WeekAhead_NO_2_to_NL', 'Aggregate_Water_Reservoirs_NO_2', 'Net_Flow_NO_2_to_NL', 'Net_Flow_NO_2_to_DE_LU']
    


    
![png](output_21_13.png)
    


    Visualizing columns 29 to 32: ['Net_Flow_NO_2_to_GB', 'Net_Flow_NO_2_to_NO_5', 'Weekday', 'Is_Weekend']
    


    
![png](output_21_15.png)
    



```python
# Calculate the correlation matrix
correlation_matrix = merged_data_no_outliers.corr()

# Display correlations of all variables with the target variable
relevant_features = correlation_matrix['DA_prices_NO_2'].sort_values(ascending=False)
print("Correlation with DA_prices_NO2:\n", relevant_features)
```

    Correlation with DA_prices_NO2:
     DA_prices_NO_2                     1.000000
    Prev_Day_DA_prices_NO_2            0.947063
    Generation_forecast_NO_2           0.712340
    Load_forecast_NO_2                 0.610133
    Load_forecast_NO_5                 0.585418
    Generation_forecast_NO_5           0.529345
    Load_forecast_DK                   0.412588
    Load_forecast_NL                   0.314096
    Load_forecast_DE_LU                0.305840
    Generation_forecast_NL             0.249181
    Generation_forecast_DE_LU          0.160235
    Net_Flow_NO_2_to_NO_5              0.121989
    Generation_forecast_DK             0.068480
    Net_Flow_NO_2_to_DE_LU             0.064849
    NTC_WeekAhead_NO_2_to_NL           0.045729
    Wind Offshore_NL                  -0.018420
    Wind Onshore_DE_LU                -0.028721
    Solar_NL                          -0.034521
    Is_Weekend                        -0.057922
    Wind Onshore_NL                   -0.060230
    Wind Onshore_NO_2                 -0.069288
    Wind Offshore_DE_LU               -0.087886
    Weekday                           -0.099498
    Solar_DE_LU                       -0.111713
    Net_Flow_NO_2_to_NL               -0.126283
    Solar_DK                          -0.140110
    Wind Onshore_NO_1                 -0.149158
    Net_Flow_NO_2_to_GB               -0.160249
    Wind Onshore_DK                   -0.166296
    Wind Offshore_DK                  -0.169140
    Aggregate_Water_Reservoirs_NO_2   -0.185401
    Generation_forecast_NO_1          -0.307114
    Name: DA_prices_NO_2, dtype: float64
    


```python
from statsmodels.stats.outliers_influence import variance_inflation_factor
from statsmodels.tools.tools import add_constant

# Add a constant column to the data for VIF calculation (the intercept in a regression model)
X = add_constant(merged_data_no_outliers.drop('DA_prices_NO_2', axis=1))

# Calculate VIF for each feature
vif_data = pd.DataFrame()
vif_data['Feature'] = X.columns
vif_data['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]

# Display VIF for each feature
print(vif_data)
```

                                Feature         VIF
    0                             const  508.105721
    1           Prev_Day_DA_prices_NO_2    3.524752
    2                Load_forecast_NO_2   17.998573
    3                Load_forecast_NO_5   15.369641
    4                  Load_forecast_DK    9.553905
    5                  Load_forecast_NL    4.759584
    6               Load_forecast_DE_LU   13.396777
    7                 Wind Onshore_NO_2    2.005480
    8                 Wind Onshore_NO_1    1.478677
    9                          Solar_DK    5.799943
    10                 Wind Offshore_DK   11.676218
    11                  Wind Onshore_DK   16.072229
    12                         Solar_NL    3.196035
    13                 Wind Offshore_NL   10.469599
    14                  Wind Onshore_NL   12.778545
    15                      Solar_DE_LU    8.497328
    16              Wind Offshore_DE_LU    4.193924
    17               Wind Onshore_DE_LU   10.920764
    18         Generation_forecast_NO_2    9.589251
    19         Generation_forecast_NO_1    3.965410
    20         Generation_forecast_NO_5    7.151177
    21           Generation_forecast_DK   27.911111
    22           Generation_forecast_NL    5.167929
    23        Generation_forecast_DE_LU   22.251512
    24         NTC_WeekAhead_NO_2_to_NL    1.623518
    25  Aggregate_Water_Reservoirs_NO_2    2.351927
    26              Net_Flow_NO_2_to_NL    2.868207
    27           Net_Flow_NO_2_to_DE_LU    5.676712
    28              Net_Flow_NO_2_to_GB    1.910378
    29            Net_Flow_NO_2_to_NO_5    7.649262
    30                          Weekday    2.879273
    31                       Is_Weekend    3.416162
    

# **Feature Engineering**

To enhance the predictive power of the dataset, the following features are engineered:
1. **Lagged Features**: Historical values for load and generation forecasts at intervals of 1, 7, and 30 days.
2. **Rolling Statistics**: Rolling means and standard deviations for load and generation forecasts over 3, 7, and 30 days.
3. **Relative Changes**: Percentage changes in load and generation forecasts.
4. **Interaction Terms**: Ratios and differences between load and generation values.
5. **Temporal Features**: Day of the week, month, and weekend indicators are added to capture seasonality and periodic effects.

These features are critical for capturing patterns in electricity demand, supply, and market dynamics.



```python
merged_data_no_outliers = merged_data_no_outliers.copy()

# Create lagged features for load and generation forecasts
lags = [1, 7, 30]
for lag in lags:
    merged_data_no_outliers.loc[:, f'Load_forecast_NO_2_lag_{lag}'] = merged_data_no_outliers['Load_forecast_NO_2'].shift(lag)
    merged_data_no_outliers.loc[:, f'Generation_forecast_NO_2_lag_{lag}'] = merged_data_no_outliers['Generation_forecast_NO_2'].shift(lag)

# Add rolling statistics features (mean and SD)
window_sizes = [3, 7, 30]
for window in window_sizes:
    merged_data_no_outliers.loc[:, f'Load_forecast_NO_2_roll_mean_{window}'] = (
        merged_data_no_outliers['Load_forecast_NO_2'].rolling(window=window).mean()
    )
    merged_data_no_outliers.loc[:, f'Load_forecast_NO_2_roll_std_{window}'] = (
        merged_data_no_outliers['Load_forecast_NO_2'].rolling(window=window).std()
    )
    merged_data_no_outliers.loc[:, f'Generation_forecast_NO_2_roll_mean_{window}'] = (
        merged_data_no_outliers['Generation_forecast_NO_2'].rolling(window=window).mean()
    )
    merged_data_no_outliers.loc[:, f'Generation_forecast_NO_2_roll_std_{window}'] = (
        merged_data_no_outliers['Generation_forecast_NO_2'].rolling(window=window).std()
    )

# Add relative change features
merged_data_no_outliers.loc[:, 'Load_forecast_NO_2_pct_change'] = (
    merged_data_no_outliers['Load_forecast_NO_2'].pct_change()
)
merged_data_no_outliers.loc[:, 'Generation_forecast_NO_2_pct_change'] = (
    merged_data_no_outliers['Generation_forecast_NO_2'].pct_change()
)

# Add interaction features
merged_data_no_outliers.loc[:, 'Load_Generation_ratio'] = (
    merged_data_no_outliers['Load_forecast_NO_2'] / merged_data_no_outliers['Generation_forecast_NO_2']
)
merged_data_no_outliers.loc[:, 'Load_Generation_diff'] = (
    merged_data_no_outliers['Load_forecast_NO_2'] - merged_data_no_outliers['Generation_forecast_NO_2']
)

# Add datetime features
merged_data_no_outliers.loc[:, 'Day_of_Week'] = merged_data_no_outliers.index.dayofweek  # 0=Monday, 6=Sunday
merged_data_no_outliers.loc[:, 'Month'] = merged_data_no_outliers.index.month
merged_data_no_outliers.loc[:, 'Is_Weekend'] = (merged_data_no_outliers['Day_of_Week'] >= 5).astype(int)

# Drop rows with NaN values caused by lagging, rolling, and pct_change
merged_data_no_outliers.dropna(inplace=True)


print(merged_data_no_outliers.head())
print(merged_data_no_outliers.columns)

```

                               DA_prices_NO_2  Prev_Day_DA_prices_NO_2  \
    2023-10-02 15:00:00+00:00           46.65                    46.73   
    2023-10-02 16:00:00+00:00           47.06                    46.65   
    2023-10-02 17:00:00+00:00           46.87                    47.06   
    2023-10-02 18:00:00+00:00           46.83                    46.87   
    2023-10-02 19:00:00+00:00           46.57                    46.83   
    
                               Load_forecast_NO_2  Load_forecast_NO_1  \
    2023-10-02 15:00:00+00:00              3495.0              3311.0   
    2023-10-02 16:00:00+00:00              3519.0              3324.0   
    2023-10-02 17:00:00+00:00              3592.0              3376.0   
    2023-10-02 18:00:00+00:00              3695.0              3518.0   
    2023-10-02 19:00:00+00:00              3579.0              3303.0   
    
                               Load_forecast_NO_5  Load_forecast_DK  \
    2023-10-02 15:00:00+00:00              1812.0            4546.0   
    2023-10-02 16:00:00+00:00              1830.0            4515.0   
    2023-10-02 17:00:00+00:00              1812.0            4350.0   
    2023-10-02 18:00:00+00:00              1852.0            4027.0   
    2023-10-02 19:00:00+00:00              1837.0            3824.0   
    
                               Load_forecast_NL  Load_forecast_DE_LU  \
    2023-10-02 15:00:00+00:00           10407.0              54523.0   
    2023-10-02 16:00:00+00:00           12267.0              55363.0   
    2023-10-02 17:00:00+00:00           12734.0              55710.0   
    2023-10-02 18:00:00+00:00           13035.0              55072.0   
    2023-10-02 19:00:00+00:00           12801.0              51575.0   
    
                               Wind Onshore_NO_2  Wind Onshore_NO_1  ...  \
    2023-10-02 15:00:00+00:00              173.0               62.0  ...   
    2023-10-02 16:00:00+00:00              173.0               82.0  ...   
    2023-10-02 17:00:00+00:00              176.0              102.0  ...   
    2023-10-02 18:00:00+00:00              180.0              111.0  ...   
    2023-10-02 19:00:00+00:00              185.0               73.0  ...   
    
                               Load_forecast_NO_2_roll_mean_30  \
    2023-10-02 15:00:00+00:00                      3353.633333   
    2023-10-02 16:00:00+00:00                      3364.600000   
    2023-10-02 17:00:00+00:00                      3380.266667   
    2023-10-02 18:00:00+00:00                      3400.300000   
    2023-10-02 19:00:00+00:00                      3416.366667   
    
                               Load_forecast_NO_2_roll_std_30  \
    2023-10-02 15:00:00+00:00                      255.450040   
    2023-10-02 16:00:00+00:00                      255.244926   
    2023-10-02 17:00:00+00:00                      254.263091   
    2023-10-02 18:00:00+00:00                      254.606546   
    2023-10-02 19:00:00+00:00                      249.973031   
    
                               Generation_forecast_NO_2_roll_mean_30  \
    2023-10-02 15:00:00+00:00                            6166.300000   
    2023-10-02 16:00:00+00:00                            6166.300000   
    2023-10-02 17:00:00+00:00                            6167.233333   
    2023-10-02 18:00:00+00:00                            6167.533333   
    2023-10-02 19:00:00+00:00                            6173.133333   
    
                               Generation_forecast_NO_2_roll_std_30  \
    2023-10-02 15:00:00+00:00                            332.609552   
    2023-10-02 16:00:00+00:00                            332.609552   
    2023-10-02 17:00:00+00:00                            332.592811   
    2023-10-02 18:00:00+00:00                            332.585455   
    2023-10-02 19:00:00+00:00                            329.024654   
    
                               Load_forecast_NO_2_pct_change  \
    2023-10-02 15:00:00+00:00                      -0.028357   
    2023-10-02 16:00:00+00:00                       0.006867   
    2023-10-02 17:00:00+00:00                       0.020745   
    2023-10-02 18:00:00+00:00                       0.028675   
    2023-10-02 19:00:00+00:00                      -0.031394   
    
                               Generation_forecast_NO_2_pct_change  \
    2023-10-02 15:00:00+00:00                            -0.009216   
    2023-10-02 16:00:00+00:00                             0.001469   
    2023-10-02 17:00:00+00:00                             0.006192   
    2023-10-02 18:00:00+00:00                            -0.001781   
    2023-10-02 19:00:00+00:00                            -0.018332   
    
                               Load_Generation_ratio  Load_Generation_diff  \
    2023-10-02 15:00:00+00:00               0.570333               -2633.0   
    2023-10-02 16:00:00+00:00               0.573407               -2618.0   
    2023-10-02 17:00:00+00:00               0.581700               -2583.0   
    2023-10-02 18:00:00+00:00               0.599448               -2469.0   
    2023-10-02 19:00:00+00:00               0.591472               -2472.0   
    
                               Day_of_Week  Month  
    2023-10-02 15:00:00+00:00            0     10  
    2023-10-02 16:00:00+00:00            0     10  
    2023-10-02 17:00:00+00:00            0     10  
    2023-10-02 18:00:00+00:00            0     10  
    2023-10-02 19:00:00+00:00            0     10  
    
    [5 rows x 57 columns]
    Index(['DA_prices_NO_2', 'Prev_Day_DA_prices_NO_2', 'Load_forecast_NO_2',
           'Load_forecast_NO_1', 'Load_forecast_NO_5', 'Load_forecast_DK',
           'Load_forecast_NL', 'Load_forecast_DE_LU', 'Wind Onshore_NO_2',
           'Wind Onshore_NO_1', 'Solar_DK', 'Wind Offshore_DK', 'Wind Onshore_DK',
           'Solar_NL', 'Wind Offshore_NL', 'Wind Onshore_NL', 'Solar_DE_LU',
           'Wind Offshore_DE_LU', 'Wind Onshore_DE_LU', 'Generation_forecast_NO_2',
           'Generation_forecast_NO_1', 'Generation_forecast_NO_5',
           'Generation_forecast_DK', 'Generation_forecast_NL',
           'Generation_forecast_DE_LU', 'NTC_WeekAhead_NO_2_to_NL',
           'Aggregate_Water_Reservoirs_NO_2', 'Net_Flow_NO_2_to_NL',
           'Net_Flow_NO_2_to_DE_LU', 'Net_Flow_NO_2_to_GB',
           'Net_Flow_NO_2_to_NO_5', 'Weekday', 'Is_Weekend',
           'Load_forecast_NO_2_lag_1', 'Generation_forecast_NO_2_lag_1',
           'Load_forecast_NO_2_lag_7', 'Generation_forecast_NO_2_lag_7',
           'Load_forecast_NO_2_lag_30', 'Generation_forecast_NO_2_lag_30',
           'Load_forecast_NO_2_roll_mean_3', 'Load_forecast_NO_2_roll_std_3',
           'Generation_forecast_NO_2_roll_mean_3',
           'Generation_forecast_NO_2_roll_std_3', 'Load_forecast_NO_2_roll_mean_7',
           'Load_forecast_NO_2_roll_std_7', 'Generation_forecast_NO_2_roll_mean_7',
           'Generation_forecast_NO_2_roll_std_7',
           'Load_forecast_NO_2_roll_mean_30', 'Load_forecast_NO_2_roll_std_30',
           'Generation_forecast_NO_2_roll_mean_30',
           'Generation_forecast_NO_2_roll_std_30', 'Load_forecast_NO_2_pct_change',
           'Generation_forecast_NO_2_pct_change', 'Load_Generation_ratio',
           'Load_Generation_diff', 'Day_of_Week', 'Month'],
          dtype='object')
    


```python
len(merged_data_no_outliers.columns)
```




    57




```python
# Correlation Matrix Heatmap

threshold = 0.4

correlation_matrix = merged_data_no_outliers.corr()

# Filter out features with low correlation to the target or low maximum correlation overall
low_corr_features = [
    col for col in correlation_matrix.columns
    if (abs(correlation_matrix.loc['DA_prices_NO_2', col]) < threshold) or
       (correlation_matrix[col].abs().max() < threshold)
]

# Filter the correlation matrix to exclude low-correlation features
filtered_corr_matrix = correlation_matrix.drop(index=low_corr_features, columns=low_corr_features)

# Mask the upper triangle of the filtered correlation matrix
mask = np.triu(np.ones_like(filtered_corr_matrix, dtype=bool))

# Create the heatmap
plt.figure(figsize=(12, 10))
sns.heatmap(filtered_corr_matrix, annot=True, cmap='coolwarm', cbar=True,
            mask=mask, annot_kws={"size": 8}, fmt='.2f', square=True)

plt.xticks(rotation=45, ha='right')
plt.yticks(rotation=0, ha='right')
plt.title('Filtered Correlation Matrix (Triangle Format)')

plt.tight_layout()
plt.show()
```


    
![png](output_27_0.png)
    



```python
# Calculate the correlation matrix
correlation_matrix_2 = merged_data_no_outliers.corr()

# Display correlations of all variables with the target variable
relevant_features_2 = correlation_matrix_2['DA_prices_NO_2'].sort_values(ascending=False)
print("Correlation with DA_prices_NO2:\n", relevant_features_2)
```

    Correlation with DA_prices_NO2:
     DA_prices_NO_2                           1.000000
    Prev_Day_DA_prices_NO_2                  0.947066
    Generation_forecast_NO_2                 0.712321
    Generation_forecast_NO_2_roll_mean_3     0.689470
    Generation_forecast_NO_2_lag_1           0.680431
    Generation_forecast_NO_2_roll_mean_7     0.616366
    Load_forecast_NO_2                       0.610201
    Load_forecast_NO_2_roll_mean_3           0.604992
    Load_forecast_NO_2_lag_1                 0.603549
    Load_forecast_NO_1                       0.597548
    Load_forecast_NO_5                       0.585167
    Load_forecast_NO_2_roll_mean_7           0.579344
    Load_forecast_NO_2_roll_mean_30          0.557083
    Generation_forecast_NO_5                 0.531902
    Generation_forecast_NO_2_roll_mean_30    0.511284
    Load_forecast_NO_2_lag_7                 0.508534
    Load_forecast_NO_2_lag_30                0.493811
    Load_forecast_DK                         0.412624
    Generation_forecast_NO_2_lag_7           0.408183
    Load_forecast_NL                         0.313677
    Load_forecast_DE_LU                      0.305345
    Load_forecast_NO_2_roll_std_30           0.276644
    Generation_forecast_NO_2_lag_30          0.254371
    Generation_forecast_NL                   0.248563
    Generation_forecast_DE_LU                0.158960
    Load_forecast_NO_2_roll_std_7            0.127233
    Net_Flow_NO_2_to_NO_5                    0.119916
    Load_forecast_NO_2_roll_std_3            0.101655
    Generation_forecast_NO_2_roll_std_30     0.082347
    Generation_forecast_NO_2_pct_change      0.080010
    Net_Flow_NO_2_to_DE_LU                   0.066482
    Generation_forecast_DK                   0.066294
    NTC_WeekAhead_NO_2_to_NL                 0.042801
    Load_forecast_NO_2_pct_change            0.027316
    Generation_forecast_NO_2_roll_std_7     -0.013700
    Wind Offshore_NL                        -0.018341
    Generation_forecast_NO_2_roll_std_3     -0.021369
    Wind Onshore_DE_LU                      -0.030295
    Solar_NL                                -0.034219
    Is_Weekend                              -0.056718
    Wind Onshore_NL                         -0.060453
    Wind Onshore_NO_2                       -0.071437
    Month                                   -0.080731
    Wind Offshore_DE_LU                     -0.089119
    Day_of_Week                             -0.099373
    Weekday                                 -0.099373
    Solar_DE_LU                             -0.112021
    Net_Flow_NO_2_to_NL                     -0.126052
    Solar_DK                                -0.141006
    Wind Onshore_NO_1                       -0.150365
    Net_Flow_NO_2_to_GB                     -0.159512
    Wind Onshore_DK                         -0.167956
    Wind Offshore_DK                        -0.170537
    Aggregate_Water_Reservoirs_NO_2         -0.183877
    Generation_forecast_NO_1                -0.306500
    Load_Generation_ratio                   -0.380344
    Load_Generation_diff                    -0.528751
    Name: DA_prices_NO_2, dtype: float64
    


```python

```


```python
# Ensure a proper DatetimeIndex
if not isinstance(merged_data_no_outliers.index, pd.DatetimeIndex):
    raise ValueError("The index of merged_data_no_outliers must be a DatetimeIndex for proper slicing.")

#Define X,y
X = merged_data_no_outliers.drop('DA_prices_NO_2', axis=1)
y = merged_data_no_outliers['DA_prices_NO_2']

# Train/Test Split
train_data = merged_data_no_outliers.loc['2023-10-01':'2024-06-30']
test_data = merged_data_no_outliers.loc['2024-07-01':'2024-09-30']

# Separate Predictors and Target
X_train, y_train = train_data.drop('DA_prices_NO_2', axis=1), train_data['DA_prices_NO_2']
X_test, y_test = test_data.drop('DA_prices_NO_2', axis=1), test_data['DA_prices_NO_2']

print(f"X_train shape: {X_train.shape}")
print(f"X_test shape: {X_test.shape}")
print(f"Y_train shape: {y_train.shape}")
print(f"Y_test shape: {y_test.shape}")
```

    X_train shape: (4412, 55)
    X_test shape: (1412, 55)
    Y_train shape: (4412,)
    Y_test shape: (1412,)
    


```python
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()

# Fit the scaler on the training data and transform both training and testing sets
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Verify the scaling by checking mean and standard deviation of the training set
scaled_summary = {
    "Training Set Mean (Scaled)": X_train_scaled.mean(axis=0),
    "Training Set Std Dev (Scaled)": X_train_scaled.std(axis=0)
}

scaled_summary
```




    {'Training Set Mean (Scaled)': array([-1.54605854e-16, -5.15352846e-17, -2.06141138e-16, -1.54605854e-16,
             2.57676423e-16,  1.67489675e-16, -7.73029268e-17,  1.93257317e-17,
             0.00000000e+00, -2.31908780e-16, -7.73029268e-17,  0.00000000e+00,
             7.73029268e-17,  5.15352846e-17,  3.86514634e-17, -7.73029268e-17,
             5.15352846e-17,  1.80373496e-16,  1.54605854e-16, -1.03070569e-16,
            -1.28838211e-16,  3.86514634e-17, -2.57676423e-16, -1.03070569e-16,
             1.54605854e-16,  2.57676423e-17,  0.00000000e+00,  1.54605854e-16,
            -7.73029268e-17, -1.25617256e-16,  1.22396301e-16, -6.18423415e-16,
            -1.41722033e-16,  0.00000000e+00, -2.19024959e-16, -1.54605854e-16,
            -1.54605854e-16,  1.54605854e-16,  2.57676423e-17, -3.09211707e-16,
            -8.37448374e-17, -7.21493984e-16,  5.15352846e-17, -2.57676423e-17,
             5.15352846e-17,  5.15352846e-17, -5.15352846e-17, -5.92655772e-16,
             2.57676423e-16,  6.44191057e-18, -1.32864405e-17, -3.09211707e-16,
             3.86514634e-17, -1.25617256e-16,  1.28838211e-16]),
     'Training Set Std Dev (Scaled)': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
            1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
            1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
            1., 1., 1., 1.])}




```python
# Build the OLS model
import statsmodels.api as sm
X_train_with_constant = sm.add_constant(X_train_scaled)
X_test_with_constant = sm.add_constant(X_test_scaled)

# Fit in OLS model
ols_model = sm.OLS(y_train, X_train_with_constant).fit()

print(ols_model.summary())

# Prediction
y_pred_ols = ols_model.predict(X_test_with_constant)

# Evaluate
from sklearn.metrics import mean_squared_error
mse_ols = mean_squared_error(y_test, y_pred_ols)
print(f'Mean Squared Error (OLS): {mse_ols}')
```

                                OLS Regression Results                            
    ==============================================================================
    Dep. Variable:         DA_prices_NO_2   R-squared:                       0.929
    Model:                            OLS   Adj. R-squared:                  0.928
    Method:                 Least Squares   F-statistic:                     1072.
    Date:                Thu, 09 Jan 2025   Prob (F-statistic):               0.00
    Time:                        23:35:52   Log-Likelihood:                -13168.
    No. Observations:                4412   AIC:                         2.644e+04
    Df Residuals:                    4358   BIC:                         2.679e+04
    Df Model:                          53                                         
    Covariance Type:            nonrobust                                         
    ==============================================================================
                     coef    std err          t      P>|t|      [0.025      0.975]
    ------------------------------------------------------------------------------
    const         58.0250      0.072    800.399      0.000      57.883      58.167
    x1            14.2514      0.155     92.061      0.000      13.948      14.555
    x2             2.6532      2.059      1.289      0.198      -1.384       6.690
    x3            -0.8381      0.315     -2.657      0.008      -1.457      -0.220
    x4             0.9045      0.220      4.108      0.000       0.473       1.336
    x5            -0.2054      0.165     -1.247      0.213      -0.528       0.118
    x6             0.0519      0.270      0.192      0.847      -0.477       0.581
    x7            -0.5474      0.108     -5.089      0.000      -0.758      -0.336
    x8            -0.0663      0.094     -0.703      0.482      -0.251       0.119
    x9            -0.7611      0.176     -4.332      0.000      -1.106      -0.417
    x10           -1.7343      0.257     -6.749      0.000      -2.238      -1.230
    x11           -2.1556      0.302     -7.136      0.000      -2.748      -1.563
    x12            0.6701      0.132      5.073      0.000       0.411       0.929
    x13           -0.6550      0.232     -2.819      0.005      -1.111      -0.200
    x14            0.3238      0.255      1.267      0.205      -0.177       0.825
    x15           -0.6263      0.211     -2.973      0.003      -1.039      -0.213
    x16           -0.1650      0.146     -1.127      0.260      -0.452       0.122
    x17            0.6763      0.252      2.679      0.007       0.181       1.171
    x18            2.0025      0.565      3.543      0.000       0.894       3.111
    x19           -0.7765      0.159     -4.871      0.000      -1.089      -0.464
    x20           -0.3993      0.226     -1.770      0.077      -0.842       0.043
    x21            4.0097      0.395     10.155      0.000       3.236       4.784
    x22           -0.8704      0.174     -5.004      0.000      -1.211      -0.529
    x23           -0.7978      0.337     -2.365      0.018      -1.459      -0.136
    x24           -0.3149      0.111     -2.842      0.005      -0.532      -0.098
    x25           -0.0325      0.155     -0.210      0.833      -0.336       0.271
    x26           -0.3624      0.126     -2.877      0.004      -0.609      -0.115
    x27           -0.2612      0.187     -1.394      0.163      -0.629       0.106
    x28           -0.0919      0.104     -0.880      0.379      -0.297       0.113
    x29           -0.4227      0.227     -1.860      0.063      -0.868       0.023
    x30           -0.1093      0.064     -1.698      0.089      -0.235       0.017
    x31            0.0352      0.142      0.248      0.805      -0.244       0.314
    x32            5.2313      2.365      2.212      0.027       0.596       9.867
    x33            0.0254      1.186      0.021      0.983      -2.300       2.351
    x34           -0.1316      0.328     -0.401      0.688      -0.774       0.511
    x35            0.2518      0.203      1.241      0.215      -0.146       0.649
    x36            0.2411      0.210      1.150      0.250      -0.170       0.652
    x37            0.0390      0.121      0.321      0.748      -0.199       0.277
    x38           -4.4453      1.605     -2.770      0.006      -7.592      -1.299
    x39            0.4342      0.096      4.504      0.000       0.245       0.623
    x40           -2.5789      1.264     -2.040      0.041      -5.058      -0.100
    x41           -0.0945      0.099     -0.952      0.341      -0.289       0.100
    x42           -1.4338      0.781     -1.836      0.066      -2.965       0.097
    x43           -0.1246      0.100     -1.246      0.213      -0.321       0.071
    x44           -0.4405      0.478     -0.921      0.357      -1.378       0.497
    x45           -0.0792      0.104     -0.762      0.446      -0.283       0.124
    x46            0.4577      0.452      1.013      0.311      -0.428       1.343
    x47            0.1999      0.096      2.077      0.038       0.011       0.389
    x48           -0.3417      0.218     -1.565      0.118      -0.770       0.086
    x49           -0.1122      0.103     -1.091      0.275      -0.314       0.089
    x50            0.6316      0.482      1.309      0.191      -0.314       1.577
    x51            0.8943      0.254      3.518      0.000       0.396       1.393
    x52           -1.9263      0.264     -7.296      0.000      -2.444      -1.409
    x53           -1.1448      0.594     -1.927      0.054      -2.309       0.020
    x54           -0.1093      0.064     -1.698      0.089      -0.235       0.017
    x55            1.3957      0.144      9.718      0.000       1.114       1.677
    ==============================================================================
    Omnibus:                     1152.392   Durbin-Watson:                   1.670
    Prob(Omnibus):                  0.000   Jarque-Bera (JB):            21524.072
    Skew:                           0.765   Prob(JB):                         0.00
    Kurtosis:                      13.712   Cond. No.                     9.53e+15
    ==============================================================================
    
    Notes:
    [1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
    [2] The smallest eigenvalue is 6.75e-28. This might indicate that there are
    strong multicollinearity problems or that the design matrix is singular.
    Mean Squared Error (OLS): 18.11427625492895
    


```python
# Model Diagnostics
# Variance Inflation Factor (VIF) Analysis
# Import necessary library for VIF
from statsmodels.stats.outliers_influence import variance_inflation_factor

X_train_df = pd.DataFrame(X_train_scaled, columns=X.columns)

vif_data = pd.DataFrame()
vif_data['Feature'] = X_train_df.columns
vif_data['VIF'] = [variance_inflation_factor(X_train_df.values, i) for i in range(X_train_df.shape[1])]
vif_data
```

    /opt/anaconda3/lib/python3.12/site-packages/statsmodels/stats/outliers_influence.py:197: RuntimeWarning: divide by zero encountered in scalar divide
      vif = 1. / (1. - r_squared_i)
    




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Feature</th>
      <th>VIF</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Prev_Day_DA_prices_NO_2</td>
      <td>4.559781</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Load_forecast_NO_2</td>
      <td>inf</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Load_forecast_NO_5</td>
      <td>18.935705</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Load_forecast_DK</td>
      <td>9.227159</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Load_forecast_NL</td>
      <td>5.165828</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Load_forecast_DE_LU</td>
      <td>13.865227</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Wind Onshore_NO_2</td>
      <td>2.201920</td>
    </tr>
    <tr>
      <th>7</th>
      <td>Wind Onshore_NO_1</td>
      <td>1.693509</td>
    </tr>
    <tr>
      <th>8</th>
      <td>Solar_DK</td>
      <td>5.873881</td>
    </tr>
    <tr>
      <th>9</th>
      <td>Wind Offshore_DK</td>
      <td>12.565921</td>
    </tr>
    <tr>
      <th>10</th>
      <td>Wind Onshore_DK</td>
      <td>17.361367</td>
    </tr>
    <tr>
      <th>11</th>
      <td>Solar_NL</td>
      <td>3.319364</td>
    </tr>
    <tr>
      <th>12</th>
      <td>Wind Offshore_NL</td>
      <td>10.270449</td>
    </tr>
    <tr>
      <th>13</th>
      <td>Wind Onshore_NL</td>
      <td>12.416782</td>
    </tr>
    <tr>
      <th>14</th>
      <td>Solar_DE_LU</td>
      <td>8.441046</td>
    </tr>
    <tr>
      <th>15</th>
      <td>Wind Offshore_DE_LU</td>
      <td>4.076972</td>
    </tr>
    <tr>
      <th>16</th>
      <td>Wind Onshore_DE_LU</td>
      <td>12.123075</td>
    </tr>
    <tr>
      <th>17</th>
      <td>Generation_forecast_NO_2</td>
      <td>inf</td>
    </tr>
    <tr>
      <th>18</th>
      <td>Generation_forecast_NO_1</td>
      <td>4.835305</td>
    </tr>
    <tr>
      <th>19</th>
      <td>Generation_forecast_NO_5</td>
      <td>9.685672</td>
    </tr>
    <tr>
      <th>20</th>
      <td>Generation_forecast_DK</td>
      <td>29.667368</td>
    </tr>
    <tr>
      <th>21</th>
      <td>Generation_forecast_NL</td>
      <td>5.756537</td>
    </tr>
    <tr>
      <th>22</th>
      <td>Generation_forecast_DE_LU</td>
      <td>21.659056</td>
    </tr>
    <tr>
      <th>23</th>
      <td>NTC_WeekAhead_NO_2_to_NL</td>
      <td>2.336156</td>
    </tr>
    <tr>
      <th>24</th>
      <td>Aggregate_Water_Reservoirs_NO_2</td>
      <td>4.555967</td>
    </tr>
    <tr>
      <th>25</th>
      <td>Net_Flow_NO_2_to_NL</td>
      <td>3.018337</td>
    </tr>
    <tr>
      <th>26</th>
      <td>Net_Flow_NO_2_to_DE_LU</td>
      <td>6.683811</td>
    </tr>
    <tr>
      <th>27</th>
      <td>Net_Flow_NO_2_to_GB</td>
      <td>2.074206</td>
    </tr>
    <tr>
      <th>28</th>
      <td>Net_Flow_NO_2_to_NO_5</td>
      <td>9.831338</td>
    </tr>
    <tr>
      <th>29</th>
      <td>Weekday</td>
      <td>inf</td>
    </tr>
    <tr>
      <th>30</th>
      <td>Is_Weekend</td>
      <td>3.849529</td>
    </tr>
    <tr>
      <th>31</th>
      <td>Load_forecast_NO_2_lag_1</td>
      <td>1063.857114</td>
    </tr>
    <tr>
      <th>32</th>
      <td>Generation_forecast_NO_2_lag_1</td>
      <td>267.690235</td>
    </tr>
    <tr>
      <th>33</th>
      <td>Load_forecast_NO_2_lag_7</td>
      <td>20.452462</td>
    </tr>
    <tr>
      <th>34</th>
      <td>Generation_forecast_NO_2_lag_7</td>
      <td>7.827766</td>
    </tr>
    <tr>
      <th>35</th>
      <td>Load_forecast_NO_2_lag_30</td>
      <td>8.362169</td>
    </tr>
    <tr>
      <th>36</th>
      <td>Generation_forecast_NO_2_lag_30</td>
      <td>2.803488</td>
    </tr>
    <tr>
      <th>37</th>
      <td>Load_forecast_NO_2_roll_mean_3</td>
      <td>490.035989</td>
    </tr>
    <tr>
      <th>38</th>
      <td>Load_forecast_NO_2_roll_std_3</td>
      <td>1.768360</td>
    </tr>
    <tr>
      <th>39</th>
      <td>Generation_forecast_NO_2_roll_mean_3</td>
      <td>304.229163</td>
    </tr>
    <tr>
      <th>40</th>
      <td>Generation_forecast_NO_2_roll_std_3</td>
      <td>1.877546</td>
    </tr>
    <tr>
      <th>41</th>
      <td>Load_forecast_NO_2_roll_mean_7</td>
      <td>116.029700</td>
    </tr>
    <tr>
      <th>42</th>
      <td>Load_forecast_NO_2_roll_std_7</td>
      <td>1.900786</td>
    </tr>
    <tr>
      <th>43</th>
      <td>Generation_forecast_NO_2_roll_mean_7</td>
      <td>43.530630</td>
    </tr>
    <tr>
      <th>44</th>
      <td>Generation_forecast_NO_2_roll_std_7</td>
      <td>2.052743</td>
    </tr>
    <tr>
      <th>45</th>
      <td>Load_forecast_NO_2_roll_mean_30</td>
      <td>38.821673</td>
    </tr>
    <tr>
      <th>46</th>
      <td>Load_forecast_NO_2_roll_std_30</td>
      <td>1.762369</td>
    </tr>
    <tr>
      <th>47</th>
      <td>Generation_forecast_NO_2_roll_mean_30</td>
      <td>9.069456</td>
    </tr>
    <tr>
      <th>48</th>
      <td>Generation_forecast_NO_2_roll_std_30</td>
      <td>2.011941</td>
    </tr>
    <tr>
      <th>49</th>
      <td>Load_forecast_NO_2_pct_change</td>
      <td>44.289469</td>
    </tr>
    <tr>
      <th>50</th>
      <td>Generation_forecast_NO_2_pct_change</td>
      <td>12.293185</td>
    </tr>
    <tr>
      <th>51</th>
      <td>Load_Generation_ratio</td>
      <td>13.262904</td>
    </tr>
    <tr>
      <th>52</th>
      <td>Load_Generation_diff</td>
      <td>inf</td>
    </tr>
    <tr>
      <th>53</th>
      <td>Day_of_Week</td>
      <td>inf</td>
    </tr>
    <tr>
      <th>54</th>
      <td>Month</td>
      <td>3.924277</td>
    </tr>
  </tbody>
</table>
</div>




```python
# Model Diagnostics
# Residuals vs Fitted Plot (Homoscedasticity Check)
# Residuals Analysis
residuals = ols_model.resid

# Plot residuals vs fitted values
plt.figure(figsize=(10, 6))
sns.scatterplot(x=ols_model.fittedvalues, y=residuals, color='blue', alpha=0.7)
plt.axhline(0, color='red', linestyle='--', linewidth=1)
plt.title("Residuals vs Fitted Values")
plt.xlabel("Fitted Values")
plt.ylabel("Residuals")
plt.show()
```


    
![png](output_34_0.png)
    



```python
# Model Diagnostics
# Q-Q Plot (Normality Check)
# Q-Q plot of residuals
sm.qqplot(residuals, line="45", fit=True)
plt.title("Q-Q Plot of Residuals")
plt.show()
```


    
![png](output_35_0.png)
    



```python
# Model Diagnostics
# Shapiro-Wilk Test Results with Conditional Message

from scipy.stats import shapiro  # Import the Shapiro-Wilk test function

# Perform Shapiro-Wilk test
shapiro_test = shapiro(residuals)

# Print results with conditional interpretation
print("### Shapiro-Wilk Test Results ###")
print(f"Test Statistic: {shapiro_test.statistic:.4f}")
print(f"p-value: {shapiro_test.pvalue:.4e}")

# Conditional message
if shapiro_test.pvalue < 0.05:
    print("\nMessage: The residuals deviate significantly from normality. Consider applying transformations "
          "(e.g., log or square root) or exploring non-linear regression techniques.")
else:
    print("\nMessage: The residuals do not significantly deviate from normality. The normality assumption is satisfied.")

```

    ### Shapiro-Wilk Test Results ###
    Test Statistic: 0.8592
    p-value: 9.0686e-53
    
    Message: The residuals deviate significantly from normality. Consider applying transformations (e.g., log or square root) or exploring non-linear regression techniques.
    


```python
# Model Diagnostics
# Leverage vs Residuals Analysis
# Leverage vs Residuals Plot
fig, ax = plt.subplots(figsize=(8, 6))
sm.graphics.plot_leverage_resid2(ols_model, ax=ax, color='orange')
plt.title('Leverage vs Residuals (Refined Log-Transformed Model)')
plt.grid(True)
plt.show()
```


    
![png](output_37_0.png)
    



```python
# Model Diagnostics
# Cook's Distance Plot
# Calculate Cook's Distance manually
influence = ols_model.get_influence()
cooks_d = influence.cooks_distance[0]

# Create the custom Cook's Distance plot with orange points
fig, ax = plt.subplots(figsize=(10, 6))
# Remove 'use_line_collection=True' since it is not available in older versions.
# Instead we plot the stem lines and markers with respective colors
markerline, stemlines, baseline = plt.stem(range(len(cooks_d)), cooks_d, markerfmt=",", basefmt=" ")
plt.setp(stemlines, 'color', 'orange')  # set stem lines color to orange
plt.setp(markerline, 'color', 'orange') # set marker line color to orange


plt.axhline(4 / len(X_train), color='red', linestyle='--', label="Threshold (4/n)")
plt.title("Cook's Distance Plot (Orange Color)")
plt.xlabel("Observation Index")
plt.ylabel("Cook's Distance")
plt.legend()
plt.grid(True)
plt.show()
```


    
![png](output_38_0.png)
    



```python
# Evaluate Test Set Performance
from sklearn.metrics import r2_score, mean_squared_error
import numpy as np
X_test_with_constant = sm.add_constant(X_test_scaled)
y_test_pred = ols_model.predict(X_test_with_constant)

# Calculate R^2 and RMSE for the test set
test_r2 = r2_score(y_test, y_test_pred)
test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))

# Display evaluation metrics
test_performance = {
    "Test R^2": test_r2,
    "Test RMSE": test_rmse
}

test_performance
```




    {'Test R^2': 0.8489659381414046, 'Test RMSE': 4.256086965151082}



# **Model Testing**

Testing differen Models and fine tuning them
1. **Simple Linear Regression**
2. **Decision Tree**
3. **Random Forest**
4. **XGBoost**
5. **SVM**

# **Simple Linear Regression**


```python
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import matplotlib.pyplot as plt

# Initialize the Linear Regression model
lr_model = LinearRegression()

# Train the model
lr_model.fit(X_train, y_train)

# Predictions and Metrics
y_pred_lr = lr_model.predict(X_test)
mse_lr = mean_squared_error(y_test, y_pred_lr)
mae_lr = mean_absolute_error(y_test, y_pred_lr)
r2_lr = r2_score(y_test, y_pred_lr)

print(f"Linear Regression - Mean Squared Error (MSE): {mse_lr}")
print(f"Linear Regression - Mean Absolute Error (MAE): {mae_lr}")
print(f"Linear Regression - R-squared (R): {r2_lr}")

# Feature Importances (For Linear Regression, coefficients represent feature importance)
lr_feature_importances = pd.DataFrame({
    'Feature': X_train.columns,
    'Importance': lr_model.coef_
}).sort_values(by='Importance', ascending=False)

print("Top 10 Feature Importances for Linear Regression:")
print(lr_feature_importances.head(10))

# Plot Actual vs Predicted Prices
plt.figure(figsize=(12, 6))
plt.plot(y_test.index, y_test, label='Actual Prices', linestyle='-', marker='o', color='blue')
plt.plot(y_test.index, y_pred_lr, label='Predicted Prices', linestyle='--', marker='x', color='orange')
plt.fill_between(y_test.index, y_pred_lr - mse_lr**0.5, y_pred_lr + mse_lr**0.5, color='green', alpha=0.2, label='Confidence Interval')
plt.xlabel('Date')
plt.ylabel('Day-Ahead Price (EUR)')
plt.title('Actual vs Predicted Day-Ahead Prices with Linear Regression')
plt.legend(loc='upper right')
plt.grid(True)
plt.tight_layout()
plt.show()
```

    Linear Regression - Mean Squared Error (MSE): 18.11427625486576
    Linear Regression - Mean Absolute Error (MAE): 2.6332384098420714
    Linear Regression - R-squared (R): 0.8489659381419316
    Top 10 Feature Importances for Linear Regression:
                                    Feature  Importance
    49        Load_forecast_NO_2_pct_change   18.046082
    50  Generation_forecast_NO_2_pct_change    8.358131
    0               Prev_Day_DA_prices_NO_2    0.785445
    54                                Month    0.376460
    30                           Is_Weekend    0.076850
    31             Load_forecast_NO_2_lag_1    0.007651
    38        Load_forecast_NO_2_roll_std_3    0.005238
    1                    Load_forecast_NO_2    0.002714
    20               Generation_forecast_DK    0.002662
    46       Load_forecast_NO_2_roll_std_30    0.002563
    


    
![png](output_42_1.png)
    


# **Decision Tree**

**Fine Tuning**


```python
from sklearn.tree import DecisionTreeRegressor
from sklearn.model_selection import GridSearchCV

#Define the base parameters and tune min_samples_split and min_samples_leaf
param_grid_1 = {
    'min_samples_split': [3, 4],  # Values to test for min_samples_split
    'min_samples_leaf': [6, 8, 10]  # Values to test for min_samples_leaf
}

base_params = {
    'max_depth': 30,
    'random_state': 42
}

#Perform Grid Search
grid_search_1 = GridSearchCV(
    estimator=DecisionTreeRegressor(**base_params),
    param_grid=param_grid_1,
    cv=3,  # Cross-validation folds
    verbose=2,  # Display progress during search
    n_jobs=-1  # Use all available processors
)

#Fit the grid search with training data
grid_search_1.fit(X_train, y_train)

#Get the best parameters and combine them with the base parameters
best_params_final = {**base_params, **grid_search_1.best_params_}

# Output best parameters
print(f"Best parameters after tuning min_samples_split and min_samples_leaf: {best_params_final}")
```

    Fitting 3 folds for each of 6 candidates, totalling 18 fits
    Best parameters after tuning min_samples_split and min_samples_leaf: {'max_depth': 30, 'random_state': 42, 'min_samples_leaf': 10, 'min_samples_split': 3}
    


```python
from sklearn.tree import DecisionTreeRegressor
from sklearn.model_selection import GridSearchCV

#Test same parameters more finely based on initial best parameters found previously for min_samples_split and min_samples_leaf
param_grid_2 = {
    'min_samples_split': [2, 3],
    'min_samples_leaf': [15, 20, 25] 
}

#Initialise the Decision Tree with the base parameters
base_params = {
    'max_depth': 30,  # Example of a parameter from Step 1
    'random_state': 42
}

#Perform Grid Search
grid_search_2 = GridSearchCV(
    estimator=DecisionTreeRegressor(**base_params),
    param_grid=param_grid_2,
    cv=3,  # Cross-validation folds
    verbose=2,  # Display progress during search
    n_jobs=-1  # Use all available processors
)

#Fit the grid search with training data
grid_search_2.fit(X_train, y_train)

#Get the best parameters and combine them with the base parameters
best_params_final = {**base_params, **grid_search_2.best_params_}

#Output best parameters
print(f"Best parameters after tuning min_samples_split and min_samples_leaf: {best_params_final}")
```

    Fitting 3 folds for each of 6 candidates, totalling 18 fits
    Best parameters after tuning min_samples_split and min_samples_leaf: {'max_depth': 30, 'random_state': 42, 'min_samples_leaf': 20, 'min_samples_split': 2}
    


```python
from sklearn.tree import DecisionTreeRegressor
from sklearn.model_selection import GridSearchCV

#Define the max_depth values to test
param_grid_3 = {
    'max_depth': [5, 10, 15, 20, 25, 30, None]
}

#Initialise the Decision Tree with the base parameters and teh bezt valuse found for min_samples_leaf and min_samples_split
base_params = {
    'max_depth': 30, 
    'random_state': 42,
    "min_samples_leaf": 20,
    'min_samples_split': 2
    
}

#Perform Grid Search
grid_search_3 = GridSearchCV(
    estimator=DecisionTreeRegressor(**base_params),
    param_grid=param_grid_3,
    cv=3,  
    verbose=2,  
    n_jobs=-1  
)

#Fit the grid search with training data
grid_search_3.fit(X_train, y_train)

#Get the best parameters and combine them with the base parameters
best_params_final = {**base_params, **grid_search_3.best_params_}

#Output best parameters
print(f"Best parameters after tuning min_samples_split and min_samples_leaf: {best_params_final}")

```

    Fitting 3 folds for each of 7 candidates, totalling 21 fits
    Best parameters after tuning min_samples_split and min_samples_leaf: {'max_depth': 15, 'random_state': 42, 'min_samples_leaf': 20, 'min_samples_split': 2}
    


```python
from sklearn.tree import DecisionTreeRegressor
from sklearn.model_selection import GridSearchCV

#Test more values of max_depth based on previous best parameter 
param_grid_4 = {
    'max_depth': [10, 11, 12, 13, 14, 15, 16, 17, 18, 19]  # Values to test for min_samples_split
}

base_params = {
    'max_depth': 30,
    'random_state': 42,
    "min_samples_leaf": 20,
    'min_samples_split': 2
    
}

#Perform Grid Search
grid_search_4 = GridSearchCV(
    estimator=DecisionTreeRegressor(**base_params),
    param_grid=param_grid_4,
    cv=3,  # Cross-validation folds
    verbose=2,  # Display progress during search
    n_jobs=-1  # Use all available processors
)

#Fit the grid search with training data
grid_search_4.fit(X_train, y_train)

#Get the best parameters and combine them with the base parameters
best_params_final = {**base_params, **grid_search_4.best_params_}

# Output best parameters
print(f"Best parameters after tuning min_samples_split and min_samples_leaf: {best_params_final}")
```

    Fitting 3 folds for each of 10 candidates, totalling 30 fits
    Best parameters after tuning min_samples_split and min_samples_leaf: {'max_depth': 11, 'random_state': 42, 'min_samples_leaf': 20, 'min_samples_split': 2}
    

**Metrics**  

Testing the performance of the model

Finding Most Important Features

plotting Predicted Vs Actual Prices


```python
from sklearn.tree import DecisionTreeRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

# Step 1: Initialise the Decision Tree Regressor with the best parameters
best_params = {
    'min_samples_leaf': 20,
    'min_samples_split': 2,
    'max_depth': 11
}

dt_model = DecisionTreeRegressor(
    min_samples_leaf=best_params['min_samples_leaf'],
    min_samples_split=best_params['min_samples_split'],
    max_depth=best_params['max_depth'],
    random_state=42
)

# Step 2: Fit the model to your training data
dt_model.fit(X_train, y_train)

# Step 3: Predict on the test data
dt_y_pred = dt_model.predict(X_test)

# Step 4: Calculate MAE, MSE, and R for Decision Tree
dt_mae = mean_absolute_error(y_test, dt_y_pred)
dt_mse = mean_squared_error(y_test, dt_y_pred)
dt_r2 = r2_score(y_test, dt_y_pred)

# Calculate Adjusted R for Decision Tree
n = len(y_test)  # Number of data points
p = X_test.shape[1]  # Number of features
dt_r2_adj = 1 - ((1 - dt_r2) * (n - 1)) / (n - p - 1)

# Step 5: Print the results for Decision Tree
print(f"Decision Tree - Mean Absolute Error (MAE): {dt_mae}")
print(f"Decision Tree - Mean Squared Error (MSE): {dt_mse}")
print(f"Decision Tree - R Score: {dt_r2}")
print(f"Decision Tree - Adjusted R: {dt_r2_adj}")
```

    Decision Tree - Mean Absolute Error (MAE): 3.0562405779189734
    Decision Tree - Mean Squared Error (MSE): 24.248176727172627
    Decision Tree - R Score: 0.7978224151918065
    Decision Tree - Adjusted R: 0.7896219969289373
    


```python
# Feature Importances
dt_feature_importances = pd.DataFrame({
    'Feature': X_train.columns,
    'Importance': dt_model.feature_importances_
}).sort_values(by='Importance', ascending=False)

print("Top 10 Feature Importances (Decision Tree):")
print(dt_feature_importances.head(10))
```

    Top 10 Feature Importances (Decision Tree):
                                    Feature  Importance
    0               Prev_Day_DA_prices_NO_2    0.951478
    50  Generation_forecast_NO_2_pct_change    0.031777
    40  Generation_forecast_NO_2_roll_std_3    0.002614
    19             Generation_forecast_NO_5    0.001698
    45      Load_forecast_NO_2_roll_mean_30    0.001508
    26               Net_Flow_NO_2_to_DE_LU    0.001139
    24      Aggregate_Water_Reservoirs_NO_2    0.000993
    18             Generation_forecast_NO_1    0.000694
    25                  Net_Flow_NO_2_to_NL    0.000667
    21               Generation_forecast_NL    0.000618
    


```python
import matplotlib.pyplot as plt
from sklearn.metrics import mean_squared_error

# Predict using the Decision Tree model
dt_y_pred = dt_model.predict(X_test)

# Calculate Mean Squared Error (MSE) for confidence interval
dt_mse = mean_squared_error(y_test, dt_y_pred)

# Plot Actual vs Predicted Prices
plt.figure(figsize=(12, 6))
plt.plot(y_test.index, y_test, label='Actual Prices', linestyle='-', marker='o', color='blue')
plt.plot(y_test.index, dt_y_pred, label='Predicted Prices', linestyle='--', marker='x', color='orange')

# Calculate confidence interval based on MSE
confidence_interval_upper = dt_y_pred + (dt_mse ** 0.5)
confidence_interval_lower = dt_y_pred - (dt_mse ** 0.5)

# Plot Confidence Interval
plt.fill_between(y_test.index, confidence_interval_lower, confidence_interval_upper, color='green', alpha=0.2, label='Confidence Interval')

# Labels and title
plt.xlabel('Date')
plt.ylabel('Day-Ahead Price (EUR)')
plt.title('Actual vs Predicted Day-Ahead Prices with Decision Tree')

# Add legend and grid
plt.legend(loc='upper right')
plt.grid(True)
plt.tight_layout()

# Show the plot
plt.show()
```


    
![png](output_52_0.png)
    


# **Random Forest**

**Fine Tuning**


```python
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import GridSearchCV

# Testing different values for min_samples_split and min_samples_leaf
param_grid_1 = {
    'min_samples_split': [3, 5, 7],
    'min_samples_leaf': [4, 5, 6]
}

#initialise the Tree parameters
best_params = {
    'n_estimators': 200,
    'max_depth': 30,
    'bootstrap': True
}


#Perform Grid Search
grid_search_1 = GridSearchCV(
    estimator=RandomForestRegressor(
        n_estimators=best_params['n_estimators'],  # Using best_params['n_estimators']
        max_depth=best_params['max_depth'],  # Using best_params['max_depth']
        bootstrap=best_params['bootstrap'],  # Using best_params['bootstrap']
        random_state=42
    ),
    param_grid=param_grid_1,
    cv=3,
    verbose=2,
    n_jobs=-1
)

#Fit the grid search with training data
grid_search_1.fit(X_train, y_train)

#print best parameters
best_params_final = {**best_params, **grid_search_1.best_params_}
print(f"Best parameters after second round: {best_params_final}")
```

    Fitting 3 folds for each of 9 candidates, totalling 27 fits
    Best parameters after second round: {'n_estimators': 200, 'max_depth': 30, 'bootstrap': True, 'min_samples_leaf': 6, 'min_samples_split': 3}
    


```python
#testing more values for tune min_samples_split and min_samples_leaf based on previous results
param_grid_2 = {
    'min_samples_split': [3, 4],
    'min_samples_leaf': [6, 8, 10]
}

#initialise the Tree parameters
best_params = {
    'n_estimators': 200,
    'max_depth': 30,
    'bootstrap': True
}

#Perform Grid Search
grid_search_2 = GridSearchCV(
    estimator=RandomForestRegressor(
        n_estimators=best_params['n_estimators'],  
        max_depth=best_params['max_depth'], 
        bootstrap=best_params['bootstrap'],
        random_state=42
    ),
    param_grid=param_grid_2,
    cv=3,
    verbose=2,
    n_jobs=-1
)

#Fit the grid search with training data
grid_search_2.fit(X_train, y_train)

#print best parameters
best_params_final = {**best_params, **grid_search_2.best_params_}
print(f"Best parameters after second round: {best_params_final}")
```

    Fitting 3 folds for each of 9 candidates, totalling 27 fits
    Best parameters after second round: {'n_estimators': 200, 'max_depth': 30, 'bootstrap': True, 'min_samples_leaf': 10, 'min_samples_split': 2}
    


```python
#using the best parameter found for min_samples_split and testing more min_samples_leaf
param_grid_3 = {
    'min_samples_leaf': [10, 20, 50]
}

#Initialising the base parameters
best_params = {
    'n_estimators': 200,
    'max_depth': 30,
    'min_samples_split': 3, #Keeping this value to avoid overfitting
    'bootstrap': True
}

#Perform Grid Search
grid_search_3 = GridSearchCV(
    estimator=RandomForestRegressor(
        min_samples_split=best_params['min_samples_split'],  # Using best_params['n_estimators']
        n_estimators=best_params['n_estimators'],  # Using best_params['n_estimators']
        max_depth=best_params['max_depth'],  # Using best_params['max_depth']
        bootstrap=best_params['bootstrap'],  # Using best_params['bootstrap']
        random_state=42
    ),
    param_grid=param_grid_3,
    cv=3,
    verbose=2,
    n_jobs=-1
)

#Fit the grid search with training data
grid_search_3.fit(X_train, y_train)

#print best parameters
best_params_final = {**best_params, **grid_search_3.best_params_}
print(f"Best parameters after second round: {best_params_final}")
```

    Fitting 3 folds for each of 3 candidates, totalling 9 fits
    Best parameters after second round: {'n_estimators': 200, 'max_depth': 30, 'min_samples_split': 2, 'bootstrap': True, 'min_samples_leaf': 10}
    


```python
param_grid_4 = {
    'bootstrap': [True, False]
}

#Initialising the base parameters
best_params = {
    'n_estimators': 200,
    'max_depth': 30,
    'min_samples_split': 3,
    'min_samples_leaf': 10
}

grid_search_4 = GridSearchCV(
    estimator=RandomForestRegressor(
        min_samples_split=3,  
        n_estimators=200,  
        max_depth=30,  
        min_samples_leaf = 10,
        random_state=42
    ),
    param_grid=param_grid_4,
    cv=3,
    verbose=2,
    n_jobs=-1
)

# Fit the grid search with training data
grid_search_4.fit(X_train, y_train)

# Final best parameters after the second round of tuning
best_params_final = {**best_params, **grid_search_4.best_params_}
print(f"Best parameters after second round: {best_params_final}")
```

    Fitting 3 folds for each of 2 candidates, totalling 6 fits
    Best parameters after second round: {'n_estimators': 200, 'max_depth': 30, 'min_samples_split': 3, 'min_samples_leaf': 10, 'bootstrap': True}
    


```python
#Testing different values for n_estimators and max_depth
param_grid_5 = {
    'n_estimators': [200, 250, 300],  # Different values for n_estimators
    'max_depth': [30, 40, 50]   # Different values for max_depth
}

#Initialising with base parameters based on best parameters found so far
best_params = {
    'min_samples_split': 3,
    'min_samples_leaf': 10,
    'bootstrap': True
}

#Perform Grid Search
grid_search_5 = GridSearchCV(
    estimator=RandomForestRegressor(
        min_samples_split=3,   
        min_samples_leaf = 10,
        bootstrap = True,
        random_state=42
    ),
    param_grid=param_grid_5,
    cv=3,
    verbose=2,
    n_jobs=-1
)

#Fit the grid search with training data
grid_search_5.fit(X_train, y_train)

#Final best parameters after the second round of tuning
best_params_final = {**best_params, **grid_search_5.best_params_}
print(f"Best parameters after second round: {best_params_final}")
```


```python
param_grid_6 = {
    'n_estimators': [300, 250, 400]
}

best_params = {
    'max_depth': 30,
    'min_samples_split': 3,
    'min_samples_leaf': 10,
    'bootstrap': True
}


grid_search_6 = GridSearchCV(
    estimator=RandomForestRegressor(
        min_samples_split=3,   
        min_samples_leaf = 10,
        bootstrap = True,
        max_depth = 30,
        random_state=42
    ),
    param_grid=param_grid_6,
    cv=3,
    verbose=2,
    n_jobs=-1
)

#Fit the grid search with training data
grid_search_6.fit(X_train, y_train)

#Final best parameters after the second round of tuning
best_params_final = {**best_params, **grid_search_6.best_params_}
print(f"Best parameters after second round: {best_params_final}")
```


```python
param_grid_7 = {
    'n_estimators': [500, 550, 600]
}

best_params = {
    'max_depth': 30,
    'min_samples_split': 3,
    'min_samples_leaf': 10,
    'bootstrap': True
}

grid_search_7 = GridSearchCV(
    estimator=RandomForestRegressor(
        min_samples_split=3,   
        min_samples_leaf = 10,
        bootstrap = True,
        max_depth = 30,
        random_state=42
    ),
    param_grid=param_grid_7,
    cv=3,
    verbose=2,
    n_jobs=-1
)

#Fit the grid search with training data
grid_search_7.fit(X_train, y_train)

#Final best parameters after the second round of tuning
best_params_final = {**best_params, **grid_search_7.best_params_}
print(f"Best parameters after second round: {best_params_final}")
```

**Metrics**  

Testing the performance of the model

Finding Most Important Features

plotting Predicted Vs Actual Prices


```python
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

#Define the best parameters found from GridSearchCV or RandomizedSearchCV
rf_best_params = {
    'n_estimators': 500,
    'max_depth': 30,
    'min_samples_split': 3,
    'min_samples_leaf': 10,
    'bootstrap': True
}

#Initialise the RandomForestRegressor with the best parameters
rf_model = RandomForestRegressor(
    n_estimators=rf_best_params['n_estimators'],
    max_depth=rf_best_params['max_depth'],
    min_samples_split=rf_best_params['min_samples_split'],
    min_samples_leaf=rf_best_params['min_samples_leaf'],
    bootstrap=rf_best_params['bootstrap'],
    random_state=42  # Optional: To ensure reproducibility
)

#Fit the model on the training data
rf_model.fit(X_train, y_train)

#Predict on the test data (optional, for evaluation)
rf_y_pred = rf_model.predict(X_test)

#Evaluate the model's performance (optional)
rf_mse = mean_squared_error(y_test, rf_y_pred)
rf_mae = mean_absolute_error(y_test, rf_y_pred)
rf_r2 = r2_score(y_test, rf_y_pred)

#Calculate Adjusted R for Random Forest
n = len(y_test)  # Number of data points
p = X_test.shape[1]  # Number of features
rf_r2_adj = 1 - ((1 - rf_r2) * (n - 1)) / (n - p - 1)

#Print the results for Random Forest
print(f"Random Forest - Mean Squared Error (MSE): {rf_mse}")
print(f"Random Forest - Mean Absolute Error (MAE): {rf_mae}")
print(f"Random Forest - R Score: {rf_r2}")
print(f"Random Forest - Adjusted R: {rf_r2_adj}")
```

    Random Forest - Mean Squared Error (MSE): 17.008544430651543
    Random Forest - Mean Absolute Error (MAE): 2.3303775543249468
    Random Forest - R Score: 0.8581853607888588
    Random Forest - Adjusted R: 0.8524332920892919
    


```python
#Feature Importances for Random Forest
rf_feature_importances = pd.DataFrame({
    'Feature': X_train.columns,  # Ensure X_train is a DataFrame with column names
    'Importance': rf_model.feature_importances_
}).sort_values(by='Importance', ascending=False)

#Display the top 10 features
print("Top 10 Feature Importances:")
print(rf_feature_importances.head(10))
```

    Top 10 Feature Importances:
                                    Feature  Importance
    0               Prev_Day_DA_prices_NO_2    0.938600
    50  Generation_forecast_NO_2_pct_change    0.031255
    40  Generation_forecast_NO_2_roll_std_3    0.002404
    24      Aggregate_Water_Reservoirs_NO_2    0.002346
    19             Generation_forecast_NO_5    0.002102
    18             Generation_forecast_NO_1    0.001633
    38        Load_forecast_NO_2_roll_std_3    0.001468
    49        Load_forecast_NO_2_pct_change    0.001294
    1                    Load_forecast_NO_2    0.001031
    17             Generation_forecast_NO_2    0.000997
    


```python
import matplotlib.pyplot as plt
from sklearn.metrics import mean_squared_error

#Predict using the Random Forest model
rf_y_pred = rf_model.predict(X_test)

#Plot Actual vs Predicted Prices
plt.figure(figsize=(12, 6))
plt.plot(y_test.index, y_test, label='Actual Prices', linestyle='-', marker='o', color='blue')
plt.plot(y_test.index, rf_y_pred, label='Predicted Prices', linestyle='--', marker='x', color='orange')

#Calculate confidence interval based on MSE
confidence_interval_upper = rf_y_pred + (rf_mse ** 0.5)
confidence_interval_lower = rf_y_pred - (rf_mse ** 0.5)

#Plot Confidence Interval
plt.fill_between(y_test.index, confidence_interval_lower, confidence_interval_upper, color='green', alpha=0.2, label='Confidence Interval')

# Labels and title
plt.xlabel('Date')
plt.ylabel('Day-Ahead Price (EUR)')
plt.title('Actual vs Predicted Day-Ahead Prices with Random Forest')

#Add legend and grid
plt.legend(loc='upper right')
plt.grid(True)
plt.tight_layout()

#Show the plot
plt.show()
```


    
![png](output_65_0.png)
    


# **XGBoost**

**Fine Tuning**


```python
from sklearn.model_selection import RandomizedSearchCV
import xgboost as xgb

#Initialise the model with fixed parameters
fixed_params = {
    'learning_rate': 0.1,  # Fixed
    'n_estimators': 1000,  # Fixed
    'max_depth': 5,  # Fixed
    'min_child_weight': 1,  # Fixed
    'gamma': 0,  # Fixed
    'subsample': 0.8,  # Fixed
    'colsample_bytree': 0.8,  # Fixed
    'nthread': 4,  # Fixed
    'scale_pos_weight': 1,  # Fixed
    'seed': 27  # Fixed
}

xgb_model = xgb.XGBRegressor(**fixed_params)
```

    [CV] END ................................min_samples_leaf=10; total time=  39.7s
    [CV] END ................................min_samples_leaf=50; total time=  28.8s
    [CV] END .....................................bootstrap=True; total time=  40.1s
    


```python
from sklearn.model_selection import GridSearchCV

# Define the parameter grid for tuning max_depth and min_child_weight
param_grid = {
    'max_depth': [3, 5, 7, 9],
    'min_child_weight': [1, 3, 5]
}

# Set up GridSearchCV
grid_search = GridSearchCV(
    estimator=xgb_model,
    param_grid=param_grid,
    cv=3,  # Cross-validation
    verbose=2,  # Detailed progress messages
    n_jobs=-1  # Use all available processors
)

# Fit the model on the training data
grid_search.fit(X_train, y_train)

# Get the best model and its parameters
best_model = grid_search.best_estimator_
print(f"Best parameters: {grid_search.best_params_}")
```

    Fitting 3 folds for each of 12 candidates, totalling 36 fits
    Best parameters: {'max_depth': 3, 'min_child_weight': 3}
    


```python
# Define the parameter grid for tuning max_depth and min_child_weight
param_grid = {
    'max_depth': [2, 3, 4],
    'min_child_weight': [1, 2]
}

# Set up GridSearchCV
grid_search = GridSearchCV(
    estimator=xgb_model,
    param_grid=param_grid,
    cv=3,  # Cross-validation
    verbose=2,  # Detailed progress messages
    n_jobs=-1  # Use all available processors
)

# Fit the model on the training data
grid_search.fit(X_train, y_train)

# Get the best model and its parameters
best_model = grid_search.best_estimator_
print(f"Best parameters: {grid_search.best_params_}")
```

    Fitting 3 folds for each of 6 candidates, totalling 18 fits
    Best parameters: {'max_depth': 2, 'min_child_weight': 1}
    


```python
from sklearn.model_selection import RandomizedSearchCV
import xgboost as xgb

#Initialize the model with fixed parameters
fixed_params = {
    'learning_rate': 0.1,  # Fixed
    'n_estimators': 1000,  # Fixed
    'max_depth': 3,  # Fixed
    'min_child_weight': 2,  # Fixed
    'gamma': 0,  # Fixed
    'subsample': 0.8,  # Fixed
    'colsample_bytree': 0.8,  # Fixed
    'nthread': 4,  # Fixed
    'scale_pos_weight': 1,  # Fixed
    'seed': 27  # Fixed
}

xgb_model = xgb.XGBRegressor(**fixed_params)
```


```python
from sklearn.model_selection import GridSearchCV

#Define the parameter grid for gamma
param_test = {
    'gamma': [i/10.0 for i in range(0, 5)]  # Testing values: [0.0, 0.1, 0.2, 0.3, 0.4]
}

#Perform GridSearchCV with XGBRegressor and your defined parameter grid
grid_search = GridSearchCV(
    estimator=xgb_model,  # xgb_model should already be initialized with your fixed parameters
    param_grid=param_test,
    cv=3,  # Cross-validation
    verbose=2,
    n_jobs=-1
)

#Fit the model to your training data
grid_search.fit(X_train, y_train)

#Get the best model and its parameters
best_model = grid_search.best_estimator_
print(f"Best parameters for gamma: {grid_search.best_params_}")
```

    Fitting 3 folds for each of 5 candidates, totalling 15 fits
    Best parameters for gamma: {'gamma': 0.1}
    


```python
from sklearn.model_selection import RandomizedSearchCV
import xgboost as xgb

#Initialise the model with fixed parameters
fixed_params = {
    'learning_rate': 0.1,  # Fixed
    'n_estimators': 1000,  # Fixed
    'max_depth': 3,  # Fixed
    'min_child_weight': 2,  # Fixed
    'gamma': 0.3,  # Fixed
    'subsample': 0.8,  # Fixed
    'colsample_bytree': 0.8,  # Fixed
    'nthread': 4,  # Fixed
    'scale_pos_weight': 1,  # Fixed
    'seed': 27  # Fixed
}

xgb_model = xgb.XGBRegressor(**fixed_params)
```


```python
param_test = {
    'subsample': [i/10.0 for i in range(6, 10)],  # [0.6, 0.7, 0.8, 0.9]
    'colsample_bytree': [i/10.0 for i in range(6, 10)]  # [0.6, 0.7, 0.8, 0.9]
}

#Perform GridSearchCV with XGBRegressor and your defined parameter grid
grid_search = GridSearchCV(
    estimator=xgb_model,  # xgb_model should already be initialized with your fixed parameters
    param_grid=param_test,
    cv=3,  # Cross-validation
    verbose=2,
    n_jobs=-1
)

#Fit the model to your training data
grid_search.fit(X_train, y_train)

#Get the best model and its parameters
best_model = grid_search.best_estimator_
print(f"Best parameters for subsample and colsample_bytree: {grid_search.best_params_}")
```

    Fitting 3 folds for each of 16 candidates, totalling 48 fits
    Best parameters for subsample and colsample_bytree: {'colsample_bytree': 0.9, 'subsample': 0.6}
    


```python
param_test = {
 'subsample':[i/100.0 for i in range(75,90,5)],
 'colsample_bytree':[i/100.0 for i in range(75,90,5)]
}

#Perform GridSearchCV with XGBRegressor and your defined parameter grid
grid_search = GridSearchCV(
    estimator=xgb_model,  # xgb_model should already be initialized with your fixed parameters
    param_grid=param_test,
    cv=3,  # Cross-validation
    verbose=2,
    n_jobs=-1
)

#Fit the model to your training data
grid_search.fit(X_train, y_train)

#Get the best model and its parameters
best_model = grid_search.best_estimator_
print(f"Best parameters for subsample and colsample_bytree: {grid_search.best_params_}")
```

    Fitting 3 folds for each of 9 candidates, totalling 27 fits
    Best parameters for subsample and colsample_bytree: {'colsample_bytree': 0.85, 'subsample': 0.75}
    


```python
from sklearn.model_selection import RandomizedSearchCV
import xgboost as xgb

#Initialise the model with fixed parameters
fixed_params = {
    'learning_rate': 0.1,  # Fixed
    'n_estimators': 1000,  # Fixed
    'max_depth': 3,  # Fixed
    'min_child_weight': 2,  # Fixed
    'gamma': 0.3,  # Fixed
    'subsample': 0.8,  # Fixed
    'colsample_bytree': 0.8,  # Fixed
    'nthread': 4,  # Fixed
    'scale_pos_weight': 1,  # Fixed
    'seed': 27  # Fixed
}

xgb_model = xgb.XGBRegressor(**fixed_params)
```


```python
param_test = {
    'reg_alpha': [1e-5, 1e-2, 0.1, 1, 100]
}

grid_search = GridSearchCV(
    estimator=xgb_model,  # xgb_model should already be initialized with your fixed parameters
    param_grid=param_test,
    cv=3,  # Cross-validation
    verbose=2,
    n_jobs=-1
)

#Fit the model to your training data
grid_search.fit(X_train, y_train)

#Get the best model and its parameters
best_model = grid_search.best_estimator_
print(f"Best parameters for subsample and colsample_bytree: {grid_search.best_params_}")
```

    Fitting 3 folds for each of 5 candidates, totalling 15 fits
    Best parameters for subsample and colsample_bytree: {'reg_alpha': 100}
    


```python
param_test = {
    'reg_alpha': [10, 50, 75, 100, 125, 150, 175]
}

grid_search = GridSearchCV(
    estimator=xgb_model,  # xgb_model should already be initialized with your fixed parameters
    param_grid=param_test,
    cv=3,  # Cross-validation
    verbose=2,
    n_jobs=-1
)

#Fit the model to your training data
grid_search.fit(X_train, y_train)

#Get the best model and its parameters
best_model = grid_search.best_estimator_
print(f"Best parameters for subsample and colsample_bytree: {grid_search.best_params_}")
```

    Fitting 3 folds for each of 7 candidates, totalling 21 fits
    Best parameters for subsample and colsample_bytree: {'reg_alpha': 10}
    


```python
param_test = {
    'reg_alpha': [115, 120, 125]
}

grid_search = GridSearchCV(
    estimator=xgb_model,  # xgb_model should already be initialized with your fixed parameters
    param_grid=param_test,
    cv=3,  # Cross-validation
    verbose=2,
    n_jobs=-1
)

#Fit the model to your training data
grid_search.fit(X_train, y_train)

#Get the best model and its parameters
best_model = grid_search.best_estimator_
print(f"Best parameters for subsample and colsample_bytree: {grid_search.best_params_}")
```

    Fitting 3 folds for each of 3 candidates, totalling 9 fits
    Best parameters for subsample and colsample_bytree: {'reg_alpha': 120}
    

**Metrics**  

Testing the performance of the model

Finding Most Important Features

plotting Predicted Vs Actual Prices


```python
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import xgboost as xgb

# Define the best parameters found from your GridSearchCV
xgb_best_params = {
    'reg_alpha': 120,  # Best reg_alpha from grid search
    'max_depth': 3,  # Best max_depth from grid search
    'min_child_weight': 2,  # Best min_child_weight from grid search
    'gamma': 0.3,  # Best gamma from grid search
    'colsample_bytree': 0.8,  # Best colsample_bytree from grid search
    'subsample': 0.8  # Best subsample from grid search
}

#Initialise XGBoost model with the best parameters
xgb_model = xgb.XGBRegressor(
    n_estimators=5000,  # You can adjust this depending on your model tuning
    random_state=42,
    learning_rate=0.01,  # Best parameter for learning_rate
    reg_alpha=xgb_best_params['reg_alpha'],  # Add the best reg_alpha
    max_depth=xgb_best_params['max_depth'],  # Add the best max_depth
    min_child_weight=xgb_best_params['min_child_weight'],  # Add the best min_child_weight
    gamma=xgb_best_params['gamma'],  # Add the best gamma
    colsample_bytree=xgb_best_params['colsample_bytree'],  # Add the best colsample_bytree
    subsample=xgb_best_params['subsample']  # Add the best subsample
)

#Train the model
xgb_model.fit(X_train, y_train)
xgb_y_pred = xgb_model.predict(X_test)

#Calculate performance metrics
xgb_mse = mean_squared_error(y_test, xgb_y_pred)
xgb_mae = mean_absolute_error(y_test, xgb_y_pred)
xgb_r2 = r2_score(y_test, xgb_y_pred)

#Calculate Adjusted R
n = len(y_test)  # Number of data points
p = X_test.shape[1]  # Number of features
xgb_r2_adj = 1 - ((1 - xgb_r2) * (n - 1)) / (n - p - 1)

#Print the results
print(f"XGBoost - Mean Squared Error (MSE): {xgb_mse}")
print(f"XGBoost - Mean Absolute Error (MAE): {xgb_mae}")
print(f"XGBoost - R Score: {xgb_r2}")
print(f"XGBoost - Adjusted R: {xgb_r2_adj}")
```

    XGBoost - Mean Squared Error (MSE): 16.321527297126178
    XGBoost - Mean Absolute Error (MAE): 2.621214093945857
    XGBoost - R Score: 0.8639136044560354
    XGBoost - Adjusted R: 0.8583938760232049
    


```python
# Feature Importances
xgb_feature_importances = pd.DataFrame({
    'Feature': X_train.columns,
    'Importance': xgb_model.feature_importances_
}).sort_values(by='Importance', ascending=False)

print("Top 10 Feature Importances:")
print(xgb_feature_importances.head(10))
```

    Top 10 Feature Importances:
                                     Feature  Importance
    0                Prev_Day_DA_prices_NO_2    0.521511
    17              Generation_forecast_NO_2    0.134814
    39  Generation_forecast_NO_2_roll_mean_3    0.111632
    54                                 Month    0.028489
    37        Load_forecast_NO_2_roll_mean_3    0.025301
    45       Load_forecast_NO_2_roll_mean_30    0.016916
    50   Generation_forecast_NO_2_pct_change    0.016149
    1                     Load_forecast_NO_2    0.014510
    24       Aggregate_Water_Reservoirs_NO_2    0.014192
    25                   Net_Flow_NO_2_to_NL    0.013275
    


```python
import matplotlib.pyplot as plt
from sklearn.metrics import mean_squared_error

# Plot Actual vs Predicted Prices
plt.figure(figsize=(12, 6))
plt.plot(y_test.index, y_test, label='Actual Prices', linestyle='-', marker='o', color='blue')
plt.plot(y_test.index, xgb_y_pred, label='Predicted Prices', linestyle='--', marker='x', color='orange')

# Calculate confidence interval based on MSE
confidence_interval_upper = xgb_y_pred + (xgb_mse ** 0.5)
confidence_interval_lower = xgb_y_pred - (xgb_mse ** 0.5)

# Plot Confidence Interval
plt.fill_between(y_test.index, confidence_interval_lower, confidence_interval_upper, color='green', alpha=0.2, label='Confidence Interval')

# Labels and title
plt.xlabel('Date')
plt.ylabel('Day-Ahead Price (EUR)')
plt.title('Actual vs Predicted Day-Ahead Prices with XGBoost')

# Add legend and grid
plt.legend(loc='upper right')
plt.grid(True)
plt.tight_layout()

# Show the plot
plt.show()
```


    
![png](output_83_0.png)
    


# **SVM**


```python
from sklearn.svm import SVR
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.model_selection import cross_val_score, GridSearchCV
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
import numpy as np

# Ensure your training and testing data are already defined (X_train, X_test, y_train, y_test)

# 1.Scaling the Data: Standardize features for better performance with SVM.
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# 2.Train the Support Vector Machine (SVM) model
svm_model = SVR(kernel='rbf')  # You can change the kernel if needed (e.g., 'linear', 'poly', 'rbf')
svm_model.fit(X_train_scaled, y_train)

# 3.Make predictions using the trained model
y_pred_svm = svm_model.predict(X_test_scaled)

# 4.Calculate Mean Squared Error (MSE)
mse_svm = mean_squared_error(y_test, y_pred_svm)

# 5.Calculate Mean Absolute Error (MAE)
mae_svm = mean_absolute_error(y_test, y_pred_svm)

# 6.Calculate R-squared (R)
r2_svm = r2_score(y_test, y_pred_svm)

# 7.Calculate Adjusted R-squared
n = len(y_test)  # Number of test samples
p = X_test.shape[1]  # Number of features
adj_r2_svm = 1 - (1 - r2_svm) * (n - 1) / (n - p - 1)

#Print results
print(f"SVM - Mean Squared Error (MSE): {mse_svm}")
print(f"SVM - Mean Absolute Error (MAE): {mae_svm}")
print(f"SVM - R-squared (R): {r2_svm}")
print(f"SVM - Adjusted R-squared (Adjusted R): {adj_r2_svm}")


print("performing cross validation...")
# 8.Cross-validation to evaluate the model performance
cv_scores = cross_val_score(svm_model, X_train_scaled, y_train, cv=5, scoring='neg_mean_squared_error')
print(f"Cross-Validation MSE: {-cv_scores.mean()} (+/- {cv_scores.std()})")

# 9.Hyperparameter tuning using GridSearchCV
param_grid = {
    'C': [0.1, 1, 10, 100],
    'gamma': [0.001, 0.01, 0.1, 1],
    'epsilon': [0.01, 0.1, 0.2, 0.3]
}
print("performing grid search...")
grid_search = GridSearchCV(SVR(), param_grid, cv=5, scoring='neg_mean_squared_error')
grid_search.fit(X_train_scaled, y_train)
print("Best parameters found: ", grid_search.best_params_)

# 10.Plot Actual vs Predicted Prices (for visualization)
plt.figure(figsize=(12, 6))
plt.plot(y_test.index, y_test, label='Actual Prices', linestyle='-', marker='o', color='blue')
plt.plot(y_test.index, y_pred_svm, label='Predicted Prices', linestyle='--', marker='x', color='orange')
plt.fill_between(y_test.index, y_pred_svm - mse_svm**0.5, y_pred_svm + mse_svm**0.5, color='green', alpha=0.2, label='Confidence Interval')
plt.xlabel('Date')
plt.ylabel('Day-Ahead Price (EUR)')
plt.title('Actual vs Predicted Day-Ahead Prices with SVM')
plt.legend(loc='upper right')
plt.grid(True)
plt.tight_layout()
plt.show()
```

    SVM - Mean Squared Error (MSE): 38.63806684516596
    SVM - Mean Absolute Error (MAE): 4.38157400129557
    SVM - R-squared (R): 0.677841714686148
    SVM - Adjusted R-squared (Adjusted R): 0.6647748225827099
    performing cross validation...
    Cross-Validation MSE: 92.12445329271713 (+/- 47.23249514263662)
    performing grid search...
    [CV] END ................................min_samples_leaf=10; total time=  40.4s
    [CV] END ................................min_samples_leaf=50; total time=  27.8s
    [CV] END ................................min_samples_leaf=50; total time=  13.9s
    [CV] END .....................................bootstrap=True; total time=  38.6s
    [CV] END ....................................bootstrap=False; total time=  48.0s
    [CV] END ....................max_depth=3, min_child_weight=1; total time=   5.6s
    [CV] END ....................max_depth=3, min_child_weight=5; total time=   6.2s
    [CV] END ....................max_depth=5, min_child_weight=1; total time=  20.9s
    [CV] END ....................max_depth=5, min_child_weight=3; total time=  25.1s
    [CV] END ....................max_depth=5, min_child_weight=5; total time=  15.8s
    [CV] END ....................max_depth=7, min_child_weight=3; total time=  39.1s
    [CV] END ....................max_depth=7, min_child_weight=5; total time=  32.2s
    [CV] END ....................max_depth=7, min_child_weight=5; total time=  34.4s
    [CV] END ....................max_depth=9, min_child_weight=3; total time=  42.7s
    [CV] END ....................max_depth=9, min_child_weight=5; total time=  35.4s
    [CV] END ....................max_depth=2, min_child_weight=1; total time=   4.4s
    [CV] END ....................max_depth=3, min_child_weight=1; total time=   7.2s
    [CV] END ....................max_depth=3, min_child_weight=2; total time=   9.3s
    [CV] END ....................max_depth=4, min_child_weight=2; total time=  17.6s
    [CV] END ..........................................gamma=0.0; total time=   6.8s
    [CV] END ..........................................gamma=0.1; total time=   8.3s
    [CV] END ..........................................gamma=0.2; total time=   7.0s
    [CV] END ..........................................gamma=0.4; total time=   5.6s
    [CV] END ................colsample_bytree=0.6, subsample=0.7; total time=   5.2s
    [CV] END ................colsample_bytree=0.6, subsample=0.8; total time=   5.2s
    [CV] END ................colsample_bytree=0.6, subsample=0.8; total time=   5.6s
    [CV] END ................colsample_bytree=0.7, subsample=0.6; total time=   6.0s
    [CV] END ................colsample_bytree=0.7, subsample=0.8; total time=   6.3s
    [CV] END ................colsample_bytree=0.7, subsample=0.9; total time=   5.7s
    [CV] END ................colsample_bytree=0.8, subsample=0.6; total time=   6.6s
    [CV] END ................colsample_bytree=0.8, subsample=0.7; total time=   8.1s
    [CV] END ................colsample_bytree=0.8, subsample=0.9; total time=   6.2s
    [CV] END ................colsample_bytree=0.9, subsample=0.6; total time=   6.7s
    [CV] END ................colsample_bytree=0.9, subsample=0.7; total time=   8.7s
    [CV] END ................colsample_bytree=0.9, subsample=0.9; total time=   7.4s
    [CV] END ..............colsample_bytree=0.75, subsample=0.75; total time=   7.0s
    [CV] END ..............colsample_bytree=0.75, subsample=0.85; total time=   6.4s
    [CV] END ...............colsample_bytree=0.8, subsample=0.75; total time=   8.1s
    [CV] END ...............colsample_bytree=0.8, subsample=0.85; total time=   6.6s
    [CV] END ..............colsample_bytree=0.85, subsample=0.75; total time=   7.8s
    [CV] END ...............colsample_bytree=0.85, subsample=0.8; total time=   7.3s
    [CV] END ..............colsample_bytree=0.85, subsample=0.85; total time=   5.5s
    [CV] END ....................................reg_alpha=1e-05; total time=   7.0s
    [CV] END ......................................reg_alpha=0.1; total time=   7.8s
    [CV] END ........................................reg_alpha=1; total time=   7.6s
    [CV] END .......................................reg_alpha=10; total time=   7.2s
    [CV] END .......................................reg_alpha=50; total time=   8.3s
    [CV] END ......................................reg_alpha=100; total time=   7.9s
    [CV] END ......................................reg_alpha=125; total time=   6.8s
    [CV] END ......................................reg_alpha=150; total time=   5.0s
    [CV] END ......................................reg_alpha=115; total time=  14.1s
    [CV] END ......................................reg_alpha=120; total time=  10.1s
    [CV] END ....................max_depth=3, min_child_weight=1; total time=   6.4s
    [CV] END ....................max_depth=3, min_child_weight=5; total time=   6.4s
    [CV] END ....................max_depth=5, min_child_weight=1; total time=  23.6s
    [CV] END ....................max_depth=5, min_child_weight=5; total time=  21.9s
    [CV] END ....................max_depth=7, min_child_weight=1; total time=  52.1s
    [CV] END ....................max_depth=7, min_child_weight=5; total time=  33.3s
    [CV] END ....................max_depth=9, min_child_weight=1; total time=  57.0s
    [CV] END ....................max_depth=9, min_child_weight=3; total time=  44.3s
    [CV] END ....................max_depth=9, min_child_weight=5; total time=  19.4s
    [CV] END ....................max_depth=2, min_child_weight=1; total time=   4.3s
    [CV] END ....................max_depth=3, min_child_weight=1; total time=   7.1s
    [CV] END ....................max_depth=3, min_child_weight=2; total time=   9.3s
    [CV] END ....................max_depth=4, min_child_weight=1; total time=  18.4s
    [CV] END ..........................................gamma=0.0; total time=   7.0s
    [CV] END ..........................................gamma=0.2; total time=   8.4s
    [CV] END ..........................................gamma=0.3; total time=   7.2s
    [CV] END ................colsample_bytree=0.6, subsample=0.6; total time=   5.3s
    [CV] END ................colsample_bytree=0.6, subsample=0.7; total time=   5.4s
    [CV] END ................colsample_bytree=0.6, subsample=0.9; total time=   5.5s
    [CV] END ................colsample_bytree=0.7, subsample=0.6; total time=   5.9s
    [CV] END ................colsample_bytree=0.7, subsample=0.7; total time=   6.4s
    [CV] END ................colsample_bytree=0.7, subsample=0.9; total time=   5.7s
    [CV] END ................colsample_bytree=0.8, subsample=0.6; total time=   6.6s
    [CV] END ................colsample_bytree=0.8, subsample=0.8; total time=   8.1s
    [CV] END ................colsample_bytree=0.8, subsample=0.9; total time=   6.2s
    [CV] END ................colsample_bytree=0.9, subsample=0.6; total time=   6.8s
    [CV] END ................colsample_bytree=0.9, subsample=0.8; total time=   8.6s
    [CV] END ................colsample_bytree=0.9, subsample=0.9; total time=   7.4s
    [CV] END ..............colsample_bytree=0.75, subsample=0.75; total time=   6.9s
    [CV] END ...............colsample_bytree=0.75, subsample=0.8; total time=   6.4s
    [CV] END ...............colsample_bytree=0.8, subsample=0.75; total time=   7.9s
    [CV] END ................colsample_bytree=0.8, subsample=0.8; total time=   6.7s
    [CV] END ...............colsample_bytree=0.8, subsample=0.85; total time=   7.7s
    [CV] END ...............colsample_bytree=0.85, subsample=0.8; total time=   7.1s
    [CV] END ..............colsample_bytree=0.85, subsample=0.85; total time=   6.0s
    [CV] END ....................................reg_alpha=1e-05; total time=   7.0s
    [CV] END ......................................reg_alpha=0.1; total time=   7.7s
    [CV] END ........................................reg_alpha=1; total time=   7.4s
    [CV] END ......................................reg_alpha=100; total time=   4.8s
    [CV] END .......................................reg_alpha=10; total time=   7.2s
    [CV] END .......................................reg_alpha=50; total time=   8.3s
    [CV] END ......................................reg_alpha=100; total time=   8.1s
    [CV] END ......................................reg_alpha=150; total time=   6.8s
    [CV] END ......................................reg_alpha=175; total time=   4.6s
    [CV] END ......................................reg_alpha=115; total time=  15.4s
    [CV] END ......................................reg_alpha=125; total time=   9.5s
    [CV] END ................................min_samples_leaf=20; total time=  32.5s
    [CV] END ................................min_samples_leaf=20; total time=  36.5s
    [CV] END .....................................bootstrap=True; total time=  39.7s
    [CV] END ....................................bootstrap=False; total time=  48.5s
    [CV] END ....................max_depth=3, min_child_weight=3; total time=   5.2s
    [CV] END ....................max_depth=3, min_child_weight=3; total time=   6.5s
    [CV] END ....................max_depth=3, min_child_weight=5; total time=   6.6s
    [CV] END ....................max_depth=5, min_child_weight=3; total time=  18.4s
    [CV] END ....................max_depth=5, min_child_weight=5; total time=  23.4s
    [CV] END ....................max_depth=7, min_child_weight=1; total time=  51.6s
    [CV] END ....................max_depth=7, min_child_weight=3; total time=  40.6s
    [CV] END ....................max_depth=9, min_child_weight=1; total time=  58.4s
    [CV] END ....................max_depth=9, min_child_weight=5; total time=  39.6s
    [CV] END ....................max_depth=2, min_child_weight=1; total time=   4.3s
    [CV] END ....................max_depth=2, min_child_weight=2; total time=   4.1s
    [CV] END ....................max_depth=3, min_child_weight=1; total time=   8.1s
    [CV] END ....................max_depth=4, min_child_weight=1; total time=  19.8s
    [CV] END ....................max_depth=4, min_child_weight=2; total time=   8.4s
    [CV] END ..........................................gamma=0.0; total time=   6.9s
    [CV] END ..........................................gamma=0.2; total time=   8.2s
    [CV] END ..........................................gamma=0.3; total time=   6.9s
    [CV] END ..........................................gamma=0.4; total time=   5.6s
    [CV] END ................colsample_bytree=0.6, subsample=0.6; total time=   5.3s
    [CV] END ................colsample_bytree=0.6, subsample=0.8; total time=   5.4s
    [CV] END ................colsample_bytree=0.6, subsample=0.9; total time=   5.6s
    [CV] END ................colsample_bytree=0.7, subsample=0.7; total time=   5.8s
    [CV] END ................colsample_bytree=0.7, subsample=0.8; total time=   6.4s
    [CV] END ................colsample_bytree=0.7, subsample=0.9; total time=   5.7s
    [CV] END ................colsample_bytree=0.8, subsample=0.7; total time=   6.5s
    [CV] END ................colsample_bytree=0.8, subsample=0.8; total time=   8.2s
    [CV] END ................colsample_bytree=0.8, subsample=0.9; total time=   6.2s
    [CV] END ................colsample_bytree=0.9, subsample=0.7; total time=   6.6s
    [CV] END ................colsample_bytree=0.9, subsample=0.8; total time=   8.8s
    [CV] END ................colsample_bytree=0.9, subsample=0.9; total time=   7.3s
    [CV] END ..............colsample_bytree=0.75, subsample=0.75; total time=   7.0s
    [CV] END ..............colsample_bytree=0.75, subsample=0.85; total time=   6.3s
    [CV] END ..............colsample_bytree=0.75, subsample=0.85; total time=   7.9s
    [CV] END ................colsample_bytree=0.8, subsample=0.8; total time=   6.7s
    [CV] END ...............colsample_bytree=0.8, subsample=0.85; total time=   7.6s
    [CV] END ..............colsample_bytree=0.85, subsample=0.75; total time=   7.1s
    [CV] END ..............colsample_bytree=0.85, subsample=0.85; total time=   6.0s
    [CV] END .....................................reg_alpha=0.01; total time=   6.8s
    [CV] END .....................................reg_alpha=0.01; total time=   7.8s
    [CV] END ........................................reg_alpha=1; total time=   7.2s
    [CV] END ......................................reg_alpha=100; total time=   5.5s
    [CV] END .......................................reg_alpha=50; total time=   7.2s
    [CV] END .......................................reg_alpha=75; total time=   8.1s
    [CV] END .......................................reg_alpha=75; total time=   7.8s
    [CV] END ......................................reg_alpha=125; total time=   7.7s
    [CV] END ......................................reg_alpha=175; total time=   4.4s
    [CV] END ......................................reg_alpha=115; total time=  15.5s
    [CV] END ......................................reg_alpha=125; total time=   9.4s
    [CV] END ................................min_samples_leaf=10; total time=  38.2s
    [CV] END ................................min_samples_leaf=20; total time=  35.0s
    [CV] END ....................................bootstrap=False; total time= 1.1min
    [CV] END ....................max_depth=3, min_child_weight=1; total time=   5.5s
    [CV] END ....................max_depth=3, min_child_weight=3; total time=   6.4s
    [CV] END ....................max_depth=5, min_child_weight=1; total time=  21.4s
    [CV] END ....................max_depth=5, min_child_weight=3; total time=  25.7s
    [CV] END ....................max_depth=7, min_child_weight=1; total time=  51.2s
    [CV] END ....................max_depth=7, min_child_weight=3; total time=  38.4s
    [CV] END ....................max_depth=9, min_child_weight=1; total time=  59.9s
    [CV] END ....................max_depth=9, min_child_weight=3; total time=  42.8s
    [CV] END ....................max_depth=2, min_child_weight=2; total time=   4.3s
    [CV] END ....................max_depth=2, min_child_weight=2; total time=   4.1s
    [CV] END ....................max_depth=3, min_child_weight=2; total time=   7.7s
    [CV] END ....................max_depth=4, min_child_weight=1; total time=  19.8s
    [CV] END ....................max_depth=4, min_child_weight=2; total time=   8.7s
    [CV] END ..........................................gamma=0.1; total time=   6.8s
    [CV] END ..........................................gamma=0.1; total time=   8.3s
    [CV] END ..........................................gamma=0.3; total time=   6.9s
    [CV] END ..........................................gamma=0.4; total time=   5.5s
    [CV] END ................colsample_bytree=0.6, subsample=0.6; total time=   5.3s
    [CV] END ................colsample_bytree=0.6, subsample=0.7; total time=   5.3s
    [CV] END ................colsample_bytree=0.6, subsample=0.9; total time=   5.5s
    [CV] END ................colsample_bytree=0.7, subsample=0.6; total time=   5.8s
    [CV] END ................colsample_bytree=0.7, subsample=0.7; total time=   6.4s
    [CV] END ................colsample_bytree=0.7, subsample=0.8; total time=   5.7s
    [CV] END ................colsample_bytree=0.8, subsample=0.6; total time=   6.5s
    [CV] END ................colsample_bytree=0.8, subsample=0.7; total time=   8.2s
    [CV] END ................colsample_bytree=0.8, subsample=0.8; total time=   6.2s
    [CV] END ................colsample_bytree=0.9, subsample=0.6; total time=   6.5s
    [CV] END ................colsample_bytree=0.9, subsample=0.7; total time=   8.8s
    [CV] END ................colsample_bytree=0.9, subsample=0.8; total time=   7.5s
    [CV] END ...............colsample_bytree=0.75, subsample=0.8; total time=   6.8s
    [CV] END ...............colsample_bytree=0.75, subsample=0.8; total time=   6.4s
    [CV] END ...............colsample_bytree=0.8, subsample=0.75; total time=   8.1s
    [CV] END ................colsample_bytree=0.8, subsample=0.8; total time=   6.8s
    [CV] END ..............colsample_bytree=0.85, subsample=0.75; total time=   7.8s
    [CV] END ...............colsample_bytree=0.85, subsample=0.8; total time=   7.4s
    [CV] END ....................................reg_alpha=1e-05; total time=   6.8s
    [CV] END .....................................reg_alpha=0.01; total time=   7.8s
    [CV] END ......................................reg_alpha=0.1; total time=   7.3s
    [CV] END ......................................reg_alpha=100; total time=   5.4s
    [CV] END .......................................reg_alpha=10; total time=   7.3s
    [CV] END .......................................reg_alpha=75; total time=   8.2s
    [CV] END ......................................reg_alpha=100; total time=   6.9s
    [CV] END ......................................reg_alpha=125; total time=   7.7s
    [CV] END ......................................reg_alpha=150; total time=   4.3s
    [CV] END ......................................reg_alpha=175; total time=   2.0s
    [CV] END ......................................reg_alpha=120; total time=  15.2s
    [CV] END ......................................reg_alpha=120; total time=   8.6s
    [CV] END ......................................reg_alpha=125; total time=   3.8s
    Best parameters found:  {'C': 100, 'epsilon': 0.1, 'gamma': 0.001}
    


    
![png](output_85_1.png)
    



```python
from sklearn.svm import SVR
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.model_selection import cross_val_score, GridSearchCV
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
import numpy as np

#Ensure your training and testing data are already defined (X_train, X_test, y_train, y_test)

# 1.Scaling the Data**: Standardize features for better performance with SVM.
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# 2.Train the Support Vector Machine (SVM) model
svm_model = SVR(kernel='rbf', C=100, epsilon=0.01, gamma=0.001)  # You can change the kernel if needed (e.g., 'linear', 'poly', 'rbf')
svm_model.fit(X_train_scaled, y_train)

# 3.Make predictions using the trained model
y_pred_svm = svm_model.predict(X_test_scaled)

# 4.Calculate Mean Squared Error (MSE)
mse_svm = mean_squared_error(y_test, y_pred_svm)

# 5.Calculate Mean Absolute Error (MAE)
mae_svm = mean_absolute_error(y_test, y_pred_svm)

# 6.Calculate R-squared (R)
r2_svm = r2_score(y_test, y_pred_svm)

# 7.Calculate Adjusted R-squared
n = len(y_test)  # Number of test samples
p = X_test.shape[1]  # Number of features
adj_r2_svm = 1 - (1 - r2_svm) * (n - 1) / (n - p - 1)

# Print results
print(f"SVM - Mean Squared Error (MSE): {mse_svm}")
print(f"SVM - Mean Absolute Error (MAE): {mae_svm}")
print(f"SVM - R-squared (R): {r2_svm}")
print(f"SVM - Adjusted R-squared (Adjusted R): {adj_r2_svm}")
```

    SVM - Mean Squared Error (MSE): 15.907216427411317
    SVM - Mean Absolute Error (MAE): 2.175435155783555
    SVM - R-squared (R): 0.8673680650507928
    SVM - Adjusted R-squared (Adjusted R): 0.8619884511701096
    


```python
from sklearn.inspection import permutation_importance

#Calculate permutation importance
result = permutation_importance(svm_model, X_test_scaled, y_test, n_repeats=10, random_state=42)

#Organise results into a DataFrame
feature_importances = pd.DataFrame({
    'Feature': X_train.columns,
    'Importance': result.importances_mean
}).sort_values(by='Importance', ascending=False)

#Display top 10 features
print("Top Feature Importances:")
print(feature_importances.head(10))
```

    Top Feature Importances:
                                    Feature  Importance
    0               Prev_Day_DA_prices_NO_2    0.466695
    51                Load_Generation_ratio    0.035778
    52                 Load_Generation_diff    0.027246
    50  Generation_forecast_NO_2_pct_change    0.020922
    9                      Wind Offshore_DK    0.018421
    8                              Solar_DK    0.016276
    18             Generation_forecast_NO_1    0.016186
    17             Generation_forecast_NO_2    0.016057
    10                      Wind Onshore_DK    0.013467
    20               Generation_forecast_DK    0.012046
    


```python
y_pred_svm = svm_model.predict(X_test_scaled)

mse_svm = mean_squared_error(y_test, y_pred_svm)
plt.figure(figsize=(12, 6))
plt.plot(y_test.index, y_test, label='Actual Prices', linestyle='-', marker='o', color='blue')
plt.plot(y_test.index, y_pred_svm, label='Predicted Prices', linestyle='--', marker='x', color='orange')

confidence_interval_upper = y_pred_svm + (mse_svm ** 0.5)
confidence_interval_lower = y_pred_svm - (mse_svm ** 0.5)

plt.fill_between(y_test.index, confidence_interval_lower, confidence_interval_upper, color='green', alpha=0.2, label='Confidence Interval')
plt.xlabel('Date')
plt.ylabel('Day-Ahead Price (EUR)')
plt.title('Actual vs Predicted Day-Ahead Prices with SVM')
plt.legend(loc='upper right')
plt.grid(True)
plt.tight_layout()

plt.show()

```


    
![png](output_88_0.png)
    



```python

```


```python

```


```python

```
